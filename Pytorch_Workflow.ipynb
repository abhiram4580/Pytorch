{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pytorch Workflow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.1.2+cu118'"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch \n",
    "from torch import nn  # nn contains all the pytorch neural network modules\n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "torch.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preparing and Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0.0000],\n",
       "         [0.0200],\n",
       "         [0.0400],\n",
       "         [0.0600],\n",
       "         [0.0800],\n",
       "         [0.1000],\n",
       "         [0.1200],\n",
       "         [0.1400],\n",
       "         [0.1600],\n",
       "         [0.1800]]),\n",
       " tensor([[0.3000],\n",
       "         [0.3140],\n",
       "         [0.3280],\n",
       "         [0.3420],\n",
       "         [0.3560],\n",
       "         [0.3700],\n",
       "         [0.3840],\n",
       "         [0.3980],\n",
       "         [0.4120],\n",
       "         [0.4260]]),\n",
       " 50,\n",
       " 50)"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Create  *known* Parameters\n",
    "weight=0.7\n",
    "bias=0.3\n",
    "\n",
    "### Create *unknown* Parameters\n",
    "start=0 \n",
    "end=1\n",
    "step=0.02\n",
    "X=torch.arange(start,end,step).unsqueeze(dim=1) \n",
    "y=weight*X+bias\n",
    "\n",
    "X[:10],y[:10],len(X),len(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Splitting data into training and test sets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40, 40, 10, 10)"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create train and test split \n",
    "train_split=int(0.8*len(X))\n",
    "X_train,y_train=X[:train_split],y[:train_split]\n",
    "X_test,y_test=X[train_split:],y[train_split:]\n",
    "len(X_train),len(y_train),len(X_test),len(y_test)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0.0000],\n",
       "         [0.0200],\n",
       "         [0.0400],\n",
       "         [0.0600],\n",
       "         [0.0800],\n",
       "         [0.1000],\n",
       "         [0.1200],\n",
       "         [0.1400],\n",
       "         [0.1600],\n",
       "         [0.1800],\n",
       "         [0.2000],\n",
       "         [0.2200],\n",
       "         [0.2400],\n",
       "         [0.2600],\n",
       "         [0.2800],\n",
       "         [0.3000],\n",
       "         [0.3200],\n",
       "         [0.3400],\n",
       "         [0.3600],\n",
       "         [0.3800],\n",
       "         [0.4000],\n",
       "         [0.4200],\n",
       "         [0.4400],\n",
       "         [0.4600],\n",
       "         [0.4800],\n",
       "         [0.5000],\n",
       "         [0.5200],\n",
       "         [0.5400],\n",
       "         [0.5600],\n",
       "         [0.5800],\n",
       "         [0.6000],\n",
       "         [0.6200],\n",
       "         [0.6400],\n",
       "         [0.6600],\n",
       "         [0.6800],\n",
       "         [0.7000],\n",
       "         [0.7200],\n",
       "         [0.7400],\n",
       "         [0.7600],\n",
       "         [0.7800]]),\n",
       " tensor([[0.3000],\n",
       "         [0.3140],\n",
       "         [0.3280],\n",
       "         [0.3420],\n",
       "         [0.3560],\n",
       "         [0.3700],\n",
       "         [0.3840],\n",
       "         [0.3980],\n",
       "         [0.4120],\n",
       "         [0.4260],\n",
       "         [0.4400],\n",
       "         [0.4540],\n",
       "         [0.4680],\n",
       "         [0.4820],\n",
       "         [0.4960],\n",
       "         [0.5100],\n",
       "         [0.5240],\n",
       "         [0.5380],\n",
       "         [0.5520],\n",
       "         [0.5660],\n",
       "         [0.5800],\n",
       "         [0.5940],\n",
       "         [0.6080],\n",
       "         [0.6220],\n",
       "         [0.6360],\n",
       "         [0.6500],\n",
       "         [0.6640],\n",
       "         [0.6780],\n",
       "         [0.6920],\n",
       "         [0.7060],\n",
       "         [0.7200],\n",
       "         [0.7340],\n",
       "         [0.7480],\n",
       "         [0.7620],\n",
       "         [0.7760],\n",
       "         [0.7900],\n",
       "         [0.8040],\n",
       "         [0.8180],\n",
       "         [0.8320],\n",
       "         [0.8460]]))"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train,y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_predictions(train_data=X_train,\n",
    "                     train_labels=y_train,\n",
    "                     test_data=X_test,\n",
    "                     test_labels=y_test,\n",
    "                     preds=None):\n",
    "   \n",
    "   plt .figure(figsize=(10,7))\n",
    "   plt.scatter(train_data,train_labels,c=\"b\",s=4,label='Training Data')\n",
    "   plt.scatter(test_data,test_labels,c=\"g\",s=4,label='Testing Data')\n",
    "   if preds is not None:\n",
    "      plt.scatter(test_data,preds,c=\"r\",s=4,label='Predictions')\n",
    "      \n",
    "   plt.legend(prop={\"size\":14});\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x700 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_predictions()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Building Pytorch Model \n",
    "class LinearRegressionModel(nn.Module): # nn.Module is a base class for all neural network modules\n",
    "     def __init__(self):\n",
    "          super().__init__() # super() is used to call the __init__() of the parent class\n",
    "          self.weights=nn.Parameter(torch.randn(1,requires_grad=True,dtype=torch.float))# nn.Parameter is a wrapper for the tensor, which tells the optimizer that this tensor should be trained\n",
    "          self.bias=nn.Parameter(torch.randn(1,requires_grad=True,dtype=torch.float))\n",
    "          # Forward method to define the computation in the model\n",
    "     def forward(self,x:torch.Tensor)->torch.tensor:\n",
    "          return self.weights*x+self.bias # this is the linear regression formula\n",
    "          \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking the contents of the Pytorch Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parameter containing:\n",
       " tensor([0.3367], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([0.1288], requires_grad=True)]"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_0 = LinearRegressionModel()\n",
    "list(model_0.parameters())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.3367], requires_grad=True)"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "torch.randn(1,requires_grad=True,dtype=torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('weights', tensor([0.3367])), ('bias', tensor([0.1288]))])"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_0.state_dict() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.7, 0.3)"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weight,bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Making Predictions using torch inference model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.3982],\n",
       "        [0.4049],\n",
       "        [0.4116],\n",
       "        [0.4184],\n",
       "        [0.4251],\n",
       "        [0.4318],\n",
       "        [0.4386],\n",
       "        [0.4453],\n",
       "        [0.4520],\n",
       "        [0.4588]])"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Make prediction with initial model\n",
    "with torch.inference_mode():\n",
    "    pred=model_0(X_test)\n",
    "    \n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x700 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_predictions(preds=pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.Training the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('weights',\n",
       "  Parameter containing:\n",
       "  tensor([0.3367], requires_grad=True)),\n",
       " ('bias',\n",
       "  Parameter containing:\n",
       "  tensor([0.1288], requires_grad=True))]"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(model_0.named_parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('weights', tensor([0.3367])), ('bias', tensor([0.1288]))])"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_0.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.L1Loss() # MAE loss is same as L1Loss\n",
    "\n",
    "# Create the optimizer\n",
    "optimizer = torch.optim.SGD(params=model_0.parameters(), # parameters of target model to optimize\n",
    "                            lr=0.01) # learning rate (how much the optimizer should change parameters at each step, hi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building a training loop in pytorch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.4811)\n",
      "Epoch 0 training loss: 0.31288138031959534 test loss: 0.48106518387794495\n",
      "tensor(0.4676)\n",
      "tensor(0.4541)\n",
      "tensor(0.4407)\n",
      "tensor(0.4272)\n",
      "tensor(0.4137)\n",
      "tensor(0.4002)\n",
      "tensor(0.3868)\n",
      "tensor(0.3733)\n",
      "tensor(0.3598)\n",
      "tensor(0.3464)\n",
      "tensor(0.3329)\n",
      "tensor(0.3194)\n",
      "tensor(0.3059)\n",
      "tensor(0.2925)\n",
      "tensor(0.2790)\n",
      "tensor(0.2655)\n",
      "tensor(0.2521)\n",
      "tensor(0.2396)\n",
      "tensor(0.2282)\n",
      "tensor(0.2173)\n",
      "tensor(0.2070)\n",
      "tensor(0.1977)\n",
      "tensor(0.1891)\n",
      "tensor(0.1810)\n",
      "tensor(0.1735)\n",
      "tensor(0.1667)\n",
      "tensor(0.1604)\n",
      "tensor(0.1547)\n",
      "tensor(0.1497)\n",
      "tensor(0.1446)\n",
      "tensor(0.1402)\n",
      "tensor(0.1365)\n",
      "tensor(0.1327)\n",
      "tensor(0.1290)\n",
      "tensor(0.1258)\n",
      "tensor(0.1227)\n",
      "tensor(0.1203)\n",
      "tensor(0.1178)\n",
      "tensor(0.1154)\n",
      "tensor(0.1136)\n",
      "tensor(0.1118)\n",
      "tensor(0.1100)\n",
      "tensor(0.1083)\n",
      "tensor(0.1065)\n",
      "tensor(0.1047)\n",
      "tensor(0.1036)\n",
      "tensor(0.1025)\n",
      "tensor(0.1014)\n",
      "tensor(0.1003)\n",
      "tensor(0.0992)\n",
      "tensor(0.0981)\n",
      "tensor(0.0970)\n",
      "tensor(0.0959)\n",
      "tensor(0.0948)\n",
      "tensor(0.0937)\n",
      "tensor(0.0926)\n",
      "tensor(0.0915)\n",
      "tensor(0.0904)\n",
      "tensor(0.0893)\n",
      "tensor(0.0889)\n",
      "tensor(0.0878)\n",
      "tensor(0.0867)\n",
      "tensor(0.0862)\n",
      "tensor(0.0851)\n",
      "tensor(0.0847)\n",
      "tensor(0.0836)\n",
      "tensor(0.0832)\n",
      "tensor(0.0821)\n",
      "tensor(0.0810)\n",
      "tensor(0.0806)\n",
      "tensor(0.0795)\n",
      "tensor(0.0791)\n",
      "tensor(0.0780)\n",
      "tensor(0.0776)\n",
      "tensor(0.0765)\n",
      "tensor(0.0754)\n",
      "tensor(0.0749)\n",
      "tensor(0.0738)\n",
      "tensor(0.0734)\n",
      "tensor(0.0723)\n",
      "tensor(0.0719)\n",
      "tensor(0.0708)\n",
      "tensor(0.0704)\n",
      "tensor(0.0693)\n",
      "tensor(0.0682)\n",
      "tensor(0.0678)\n",
      "tensor(0.0667)\n",
      "tensor(0.0663)\n",
      "tensor(0.0652)\n",
      "tensor(0.0647)\n",
      "tensor(0.0636)\n",
      "tensor(0.0625)\n",
      "tensor(0.0621)\n",
      "tensor(0.0610)\n",
      "tensor(0.0606)\n",
      "tensor(0.0595)\n",
      "tensor(0.0591)\n",
      "tensor(0.0580)\n",
      "tensor(0.0569)\n",
      "tensor(0.0565)\n",
      "Epoch 100 training loss: 0.024458957836031914 test loss: 0.05646304413676262\n",
      "tensor(0.0554)\n",
      "tensor(0.0549)\n",
      "tensor(0.0538)\n",
      "tensor(0.0534)\n",
      "tensor(0.0523)\n",
      "tensor(0.0519)\n",
      "tensor(0.0508)\n",
      "tensor(0.0497)\n",
      "tensor(0.0493)\n",
      "tensor(0.0482)\n",
      "tensor(0.0478)\n",
      "tensor(0.0467)\n",
      "tensor(0.0463)\n",
      "tensor(0.0452)\n",
      "tensor(0.0441)\n",
      "tensor(0.0436)\n",
      "tensor(0.0425)\n",
      "tensor(0.0421)\n",
      "tensor(0.0410)\n",
      "tensor(0.0406)\n",
      "tensor(0.0395)\n",
      "tensor(0.0391)\n",
      "tensor(0.0380)\n",
      "tensor(0.0369)\n",
      "tensor(0.0365)\n",
      "tensor(0.0354)\n",
      "tensor(0.0350)\n",
      "tensor(0.0338)\n",
      "tensor(0.0334)\n",
      "tensor(0.0323)\n",
      "tensor(0.0312)\n",
      "tensor(0.0308)\n",
      "tensor(0.0297)\n",
      "tensor(0.0293)\n",
      "tensor(0.0282)\n",
      "tensor(0.0278)\n",
      "tensor(0.0267)\n",
      "tensor(0.0256)\n",
      "tensor(0.0252)\n",
      "tensor(0.0241)\n",
      "tensor(0.0236)\n",
      "tensor(0.0225)\n",
      "tensor(0.0221)\n",
      "tensor(0.0210)\n",
      "tensor(0.0206)\n",
      "tensor(0.0195)\n",
      "tensor(0.0184)\n",
      "tensor(0.0180)\n",
      "tensor(0.0169)\n",
      "tensor(0.0165)\n",
      "tensor(0.0154)\n",
      "tensor(0.0150)\n",
      "tensor(0.0139)\n",
      "tensor(0.0128)\n",
      "tensor(0.0123)\n",
      "tensor(0.0112)\n",
      "tensor(0.0108)\n",
      "tensor(0.0097)\n",
      "tensor(0.0093)\n",
      "tensor(0.0082)\n",
      "tensor(0.0071)\n",
      "tensor(0.0067)\n",
      "tensor(0.0056)\n",
      "tensor(0.0052)\n",
      "tensor(0.0041)\n",
      "tensor(0.0037)\n",
      "tensor(0.0019)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "Epoch 200 training loss: 0.008932482451200485 test loss: 0.005023092031478882\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "Epoch 300 training loss: 0.008932482451200485 test loss: 0.005023092031478882\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "Epoch 400 training loss: 0.008932482451200485 test loss: 0.005023092031478882\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "Epoch 500 training loss: 0.008932482451200485 test loss: 0.005023092031478882\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "Epoch 600 training loss: 0.008932482451200485 test loss: 0.005023092031478882\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "Epoch 700 training loss: 0.008932482451200485 test loss: 0.005023092031478882\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "Epoch 800 training loss: 0.008932482451200485 test loss: 0.005023092031478882\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "Epoch 900 training loss: 0.008932482451200485 test loss: 0.005023092031478882\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "Epoch 1000 training loss: 0.008932482451200485 test loss: 0.005023092031478882\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "Epoch 1100 training loss: 0.008932482451200485 test loss: 0.005023092031478882\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "Epoch 1200 training loss: 0.008932482451200485 test loss: 0.005023092031478882\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "Epoch 1300 training loss: 0.008932482451200485 test loss: 0.005023092031478882\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "Epoch 1400 training loss: 0.008932482451200485 test loss: 0.005023092031478882\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "Epoch 1500 training loss: 0.008932482451200485 test loss: 0.005023092031478882\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "Epoch 1600 training loss: 0.008932482451200485 test loss: 0.005023092031478882\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "Epoch 1700 training loss: 0.008932482451200485 test loss: 0.005023092031478882\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "Epoch 1800 training loss: 0.008932482451200485 test loss: 0.005023092031478882\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "Epoch 1900 training loss: 0.008932482451200485 test loss: 0.005023092031478882\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "Epoch 2000 training loss: 0.008932482451200485 test loss: 0.005023092031478882\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "Epoch 2100 training loss: 0.008932482451200485 test loss: 0.005023092031478882\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "Epoch 2200 training loss: 0.008932482451200485 test loss: 0.005023092031478882\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "Epoch 2300 training loss: 0.008932482451200485 test loss: 0.005023092031478882\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "Epoch 2400 training loss: 0.008932482451200485 test loss: 0.005023092031478882\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "Epoch 2500 training loss: 0.008932482451200485 test loss: 0.005023092031478882\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "Epoch 2600 training loss: 0.008932482451200485 test loss: 0.005023092031478882\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "Epoch 2700 training loss: 0.008932482451200485 test loss: 0.005023092031478882\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "Epoch 2800 training loss: 0.008932482451200485 test loss: 0.005023092031478882\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "Epoch 2900 training loss: 0.008932482451200485 test loss: 0.005023092031478882\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "Epoch 3000 training loss: 0.008932482451200485 test loss: 0.005023092031478882\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "Epoch 3100 training loss: 0.008932482451200485 test loss: 0.005023092031478882\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "Epoch 3200 training loss: 0.008932482451200485 test loss: 0.005023092031478882\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "Epoch 3300 training loss: 0.008932482451200485 test loss: 0.005023092031478882\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "Epoch 3400 training loss: 0.008932482451200485 test loss: 0.005023092031478882\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "Epoch 3500 training loss: 0.008932482451200485 test loss: 0.005023092031478882\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "Epoch 3600 training loss: 0.008932482451200485 test loss: 0.005023092031478882\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "Epoch 3700 training loss: 0.008932482451200485 test loss: 0.005023092031478882\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "Epoch 3800 training loss: 0.008932482451200485 test loss: 0.005023092031478882\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "Epoch 3900 training loss: 0.008932482451200485 test loss: 0.005023092031478882\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "Epoch 4000 training loss: 0.008932482451200485 test loss: 0.005023092031478882\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "Epoch 4100 training loss: 0.008932482451200485 test loss: 0.005023092031478882\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "Epoch 4200 training loss: 0.008932482451200485 test loss: 0.005023092031478882\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "Epoch 4300 training loss: 0.008932482451200485 test loss: 0.005023092031478882\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "Epoch 4400 training loss: 0.008932482451200485 test loss: 0.005023092031478882\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "Epoch 4500 training loss: 0.008932482451200485 test loss: 0.005023092031478882\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "Epoch 4600 training loss: 0.008932482451200485 test loss: 0.005023092031478882\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "Epoch 4700 training loss: 0.008932482451200485 test loss: 0.005023092031478882\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "Epoch 4800 training loss: 0.008932482451200485 test loss: 0.005023092031478882\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "Epoch 4900 training loss: 0.008932482451200485 test loss: 0.005023092031478882\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "Epoch 5000 training loss: 0.008932482451200485 test loss: 0.005023092031478882\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "Epoch 5100 training loss: 0.008932482451200485 test loss: 0.005023092031478882\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "Epoch 5200 training loss: 0.008932482451200485 test loss: 0.005023092031478882\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "Epoch 5300 training loss: 0.008932482451200485 test loss: 0.005023092031478882\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "Epoch 5400 training loss: 0.008932482451200485 test loss: 0.005023092031478882\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "Epoch 5500 training loss: 0.008932482451200485 test loss: 0.005023092031478882\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "Epoch 5600 training loss: 0.008932482451200485 test loss: 0.005023092031478882\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "Epoch 5700 training loss: 0.008932482451200485 test loss: 0.005023092031478882\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "Epoch 5800 training loss: 0.008932482451200485 test loss: 0.005023092031478882\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "Epoch 5900 training loss: 0.008932482451200485 test loss: 0.005023092031478882\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "Epoch 6000 training loss: 0.008932482451200485 test loss: 0.005023092031478882\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "Epoch 6100 training loss: 0.008932482451200485 test loss: 0.005023092031478882\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "Epoch 6200 training loss: 0.008932482451200485 test loss: 0.005023092031478882\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "Epoch 6300 training loss: 0.008932482451200485 test loss: 0.005023092031478882\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "Epoch 6400 training loss: 0.008932482451200485 test loss: 0.005023092031478882\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "Epoch 6500 training loss: 0.008932482451200485 test loss: 0.005023092031478882\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "Epoch 6600 training loss: 0.008932482451200485 test loss: 0.005023092031478882\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "Epoch 6700 training loss: 0.008932482451200485 test loss: 0.005023092031478882\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "Epoch 6800 training loss: 0.008932482451200485 test loss: 0.005023092031478882\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "Epoch 6900 training loss: 0.008932482451200485 test loss: 0.005023092031478882\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "Epoch 7000 training loss: 0.008932482451200485 test loss: 0.005023092031478882\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "Epoch 7100 training loss: 0.008932482451200485 test loss: 0.005023092031478882\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "Epoch 7200 training loss: 0.008932482451200485 test loss: 0.005023092031478882\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "Epoch 7300 training loss: 0.008932482451200485 test loss: 0.005023092031478882\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "Epoch 7400 training loss: 0.008932482451200485 test loss: 0.005023092031478882\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "Epoch 7500 training loss: 0.008932482451200485 test loss: 0.005023092031478882\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "Epoch 7600 training loss: 0.008932482451200485 test loss: 0.005023092031478882\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "Epoch 7700 training loss: 0.008932482451200485 test loss: 0.005023092031478882\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "Epoch 7800 training loss: 0.008932482451200485 test loss: 0.005023092031478882\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "Epoch 7900 training loss: 0.008932482451200485 test loss: 0.005023092031478882\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "Epoch 8000 training loss: 0.008932482451200485 test loss: 0.005023092031478882\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "Epoch 8100 training loss: 0.008932482451200485 test loss: 0.005023092031478882\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "Epoch 8200 training loss: 0.008932482451200485 test loss: 0.005023092031478882\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "Epoch 8300 training loss: 0.008932482451200485 test loss: 0.005023092031478882\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "Epoch 8400 training loss: 0.008932482451200485 test loss: 0.005023092031478882\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "Epoch 8500 training loss: 0.008932482451200485 test loss: 0.005023092031478882\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "Epoch 8600 training loss: 0.008932482451200485 test loss: 0.005023092031478882\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "Epoch 8700 training loss: 0.008932482451200485 test loss: 0.005023092031478882\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "Epoch 8800 training loss: 0.008932482451200485 test loss: 0.005023092031478882\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "Epoch 8900 training loss: 0.008932482451200485 test loss: 0.005023092031478882\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "Epoch 9000 training loss: 0.008932482451200485 test loss: 0.005023092031478882\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "Epoch 9100 training loss: 0.008932482451200485 test loss: 0.005023092031478882\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "Epoch 9200 training loss: 0.008932482451200485 test loss: 0.005023092031478882\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "Epoch 9300 training loss: 0.008932482451200485 test loss: 0.005023092031478882\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "Epoch 9400 training loss: 0.008932482451200485 test loss: 0.005023092031478882\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "Epoch 9500 training loss: 0.008932482451200485 test loss: 0.005023092031478882\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "Epoch 9600 training loss: 0.008932482451200485 test loss: 0.005023092031478882\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "Epoch 9700 training loss: 0.008932482451200485 test loss: 0.005023092031478882\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "Epoch 9800 training loss: 0.008932482451200485 test loss: 0.005023092031478882\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "Epoch 9900 training loss: 0.008932482451200485 test loss: 0.005023092031478882\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "Epoch 10000 training loss: 0.008932482451200485 test loss: 0.005023092031478882\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "Epoch 10100 training loss: 0.008932482451200485 test loss: 0.005023092031478882\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "Epoch 10200 training loss: 0.008932482451200485 test loss: 0.005023092031478882\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "Epoch 10300 training loss: 0.008932482451200485 test loss: 0.005023092031478882\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "Epoch 10400 training loss: 0.008932482451200485 test loss: 0.005023092031478882\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "Epoch 10500 training loss: 0.008932482451200485 test loss: 0.005023092031478882\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "Epoch 10600 training loss: 0.008932482451200485 test loss: 0.005023092031478882\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "Epoch 10700 training loss: 0.008932482451200485 test loss: 0.005023092031478882\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "Epoch 10800 training loss: 0.008932482451200485 test loss: 0.005023092031478882\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "Epoch 10900 training loss: 0.008932482451200485 test loss: 0.005023092031478882\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "Epoch 11000 training loss: 0.008932482451200485 test loss: 0.005023092031478882\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "Epoch 11100 training loss: 0.008932482451200485 test loss: 0.005023092031478882\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "Epoch 11200 training loss: 0.008932482451200485 test loss: 0.005023092031478882\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "Epoch 11300 training loss: 0.008932482451200485 test loss: 0.005023092031478882\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "Epoch 11400 training loss: 0.008932482451200485 test loss: 0.005023092031478882\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "Epoch 11500 training loss: 0.008932482451200485 test loss: 0.005023092031478882\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "Epoch 11600 training loss: 0.008932482451200485 test loss: 0.005023092031478882\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "Epoch 11700 training loss: 0.008932482451200485 test loss: 0.005023092031478882\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "Epoch 11800 training loss: 0.008932482451200485 test loss: 0.005023092031478882\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "Epoch 11900 training loss: 0.008932482451200485 test loss: 0.005023092031478882\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "Epoch 12000 training loss: 0.008932482451200485 test loss: 0.005023092031478882\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "Epoch 12100 training loss: 0.008932482451200485 test loss: 0.005023092031478882\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "Epoch 12200 training loss: 0.008932482451200485 test loss: 0.005023092031478882\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "Epoch 12300 training loss: 0.008932482451200485 test loss: 0.005023092031478882\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "Epoch 12400 training loss: 0.008932482451200485 test loss: 0.005023092031478882\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "Epoch 12500 training loss: 0.008932482451200485 test loss: 0.005023092031478882\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "Epoch 12600 training loss: 0.008932482451200485 test loss: 0.005023092031478882\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "Epoch 12700 training loss: 0.008932482451200485 test loss: 0.005023092031478882\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "Epoch 12800 training loss: 0.008932482451200485 test loss: 0.005023092031478882\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "Epoch 12900 training loss: 0.008932482451200485 test loss: 0.005023092031478882\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "Epoch 13000 training loss: 0.008932482451200485 test loss: 0.005023092031478882\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "Epoch 13100 training loss: 0.008932482451200485 test loss: 0.005023092031478882\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "Epoch 13200 training loss: 0.008932482451200485 test loss: 0.005023092031478882\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "Epoch 13300 training loss: 0.008932482451200485 test loss: 0.005023092031478882\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "Epoch 13400 training loss: 0.008932482451200485 test loss: 0.005023092031478882\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "Epoch 13500 training loss: 0.008932482451200485 test loss: 0.005023092031478882\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "Epoch 13600 training loss: 0.008932482451200485 test loss: 0.005023092031478882\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "Epoch 13700 training loss: 0.008932482451200485 test loss: 0.005023092031478882\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "Epoch 13800 training loss: 0.008932482451200485 test loss: 0.005023092031478882\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "Epoch 13900 training loss: 0.008932482451200485 test loss: 0.005023092031478882\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "Epoch 14000 training loss: 0.008932482451200485 test loss: 0.005023092031478882\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "Epoch 14100 training loss: 0.008932482451200485 test loss: 0.005023092031478882\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "Epoch 14200 training loss: 0.008932482451200485 test loss: 0.005023092031478882\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "Epoch 14300 training loss: 0.008932482451200485 test loss: 0.005023092031478882\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "Epoch 14400 training loss: 0.008932482451200485 test loss: 0.005023092031478882\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "Epoch 14500 training loss: 0.008932482451200485 test loss: 0.005023092031478882\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "Epoch 14600 training loss: 0.008932482451200485 test loss: 0.005023092031478882\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "Epoch 14700 training loss: 0.008932482451200485 test loss: 0.005023092031478882\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "Epoch 14800 training loss: 0.008932482451200485 test loss: 0.005023092031478882\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "Epoch 14900 training loss: 0.008932482451200485 test loss: 0.005023092031478882\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "Epoch 15000 training loss: 0.008932482451200485 test loss: 0.005023092031478882\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "Epoch 15100 training loss: 0.008932482451200485 test loss: 0.005023092031478882\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "Epoch 15200 training loss: 0.008932482451200485 test loss: 0.005023092031478882\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "Epoch 15300 training loss: 0.008932482451200485 test loss: 0.005023092031478882\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "Epoch 15400 training loss: 0.008932482451200485 test loss: 0.005023092031478882\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "Epoch 15500 training loss: 0.008932482451200485 test loss: 0.005023092031478882\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "Epoch 15600 training loss: 0.008932482451200485 test loss: 0.005023092031478882\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "Epoch 15700 training loss: 0.008932482451200485 test loss: 0.005023092031478882\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "Epoch 15800 training loss: 0.008932482451200485 test loss: 0.005023092031478882\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "Epoch 15900 training loss: 0.008932482451200485 test loss: 0.005023092031478882\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "Epoch 16000 training loss: 0.008932482451200485 test loss: 0.005023092031478882\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "Epoch 16100 training loss: 0.008932482451200485 test loss: 0.005023092031478882\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "Epoch 16200 training loss: 0.008932482451200485 test loss: 0.005023092031478882\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "Epoch 16300 training loss: 0.008932482451200485 test loss: 0.005023092031478882\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "Epoch 16400 training loss: 0.008932482451200485 test loss: 0.005023092031478882\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "Epoch 16500 training loss: 0.008932482451200485 test loss: 0.005023092031478882\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "Epoch 16600 training loss: 0.008932482451200485 test loss: 0.005023092031478882\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "Epoch 16700 training loss: 0.008932482451200485 test loss: 0.005023092031478882\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "Epoch 16800 training loss: 0.008932482451200485 test loss: 0.005023092031478882\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "Epoch 16900 training loss: 0.008932482451200485 test loss: 0.005023092031478882\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "Epoch 17000 training loss: 0.008932482451200485 test loss: 0.005023092031478882\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "Epoch 17100 training loss: 0.008932482451200485 test loss: 0.005023092031478882\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "Epoch 17200 training loss: 0.008932482451200485 test loss: 0.005023092031478882\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "Epoch 17300 training loss: 0.008932482451200485 test loss: 0.005023092031478882\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "Epoch 17400 training loss: 0.008932482451200485 test loss: 0.005023092031478882\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "Epoch 17500 training loss: 0.008932482451200485 test loss: 0.005023092031478882\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "Epoch 17600 training loss: 0.008932482451200485 test loss: 0.005023092031478882\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "Epoch 17700 training loss: 0.008932482451200485 test loss: 0.005023092031478882\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "Epoch 17800 training loss: 0.008932482451200485 test loss: 0.005023092031478882\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "Epoch 17900 training loss: 0.008932482451200485 test loss: 0.005023092031478882\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "Epoch 18000 training loss: 0.008932482451200485 test loss: 0.005023092031478882\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "Epoch 18100 training loss: 0.008932482451200485 test loss: 0.005023092031478882\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "Epoch 18200 training loss: 0.008932482451200485 test loss: 0.005023092031478882\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "Epoch 18300 training loss: 0.008932482451200485 test loss: 0.005023092031478882\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "Epoch 18400 training loss: 0.008932482451200485 test loss: 0.005023092031478882\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "Epoch 18500 training loss: 0.008932482451200485 test loss: 0.005023092031478882\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "Epoch 18600 training loss: 0.008932482451200485 test loss: 0.005023092031478882\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "Epoch 18700 training loss: 0.008932482451200485 test loss: 0.005023092031478882\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "Epoch 18800 training loss: 0.008932482451200485 test loss: 0.005023092031478882\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "Epoch 18900 training loss: 0.008932482451200485 test loss: 0.005023092031478882\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "Epoch 19000 training loss: 0.008932482451200485 test loss: 0.005023092031478882\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "Epoch 19100 training loss: 0.008932482451200485 test loss: 0.005023092031478882\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "Epoch 19200 training loss: 0.008932482451200485 test loss: 0.005023092031478882\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "Epoch 19300 training loss: 0.008932482451200485 test loss: 0.005023092031478882\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "Epoch 19400 training loss: 0.008932482451200485 test loss: 0.005023092031478882\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "Epoch 19500 training loss: 0.008932482451200485 test loss: 0.005023092031478882\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "Epoch 19600 training loss: 0.008932482451200485 test loss: 0.005023092031478882\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "Epoch 19700 training loss: 0.008932482451200485 test loss: 0.005023092031478882\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "Epoch 19800 training loss: 0.008932482451200485 test loss: 0.005023092031478882\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "Epoch 19900 training loss: 0.008932482451200485 test loss: 0.005023092031478882\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n",
      "tensor(0.0050)\n",
      "tensor(0.0084)\n"
     ]
    }
   ],
   "source": [
    "epochs=20000\n",
    "epoch_count=[]\n",
    "loss_values=[]\n",
    "test_loss_values=[]\n",
    "# 0. Loop through the data\n",
    "for epoch in range(epochs):\n",
    "    model_0.train()\n",
    "    # 1.Forward Pass\n",
    "    y_pred=model_0(X_train)\n",
    "    # 2.Calaculate the Loss\n",
    "    loss=loss_fn(y_pred,y_train)\n",
    "    \n",
    "    # 3.Optimizer zero grad\n",
    "    optimizer.zero_grad()\n",
    "    # 4.Backward Pass\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    model_0.eval()\n",
    "    with torch.inference_mode():\n",
    "        preds=model_0(X_test)\n",
    "        test_loss=loss_fn(preds,y_test)\n",
    "        print(test_loss)\n",
    "        if epoch%100==0:\n",
    "            epoch_count.append(epoch)\n",
    "            loss_values.append(loss)\n",
    "            test_loss_values.append(test_loss)\n",
    "            print(f\"Epoch {epoch} training loss: {loss} test loss: {test_loss}\")\n",
    "            \n",
    "        \n",
    "     \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])\n"
     ]
    }
   ],
   "source": [
    "print(model_0.state_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "loss_values_np = np.array(torch.tensor(loss_values).cpu().detach().numpy())\n",
    "test_loss_values_np = np.array(torch.tensor(test_loss_values).cpu().detach().numpy())\n",
    "epoch_count_np = np.array(epoch_count)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x1faa5a2bbd0>"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(epoch_count_np,loss_values_np,label=\"Training Loss\")\n",
    "plt.plot(epoch_count_np,test_loss_values_np,label=\"Test Loss\")\n",
    "plt.title(\"Training and test loss curves\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.inference_mode():\n",
    "    y_preds=model_0(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x700 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_predictions(preds=y_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.7, 0.3)"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weight,bias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving a Pytorch Model\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_0.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<generator object Module.parameters at 0x000001FAA5A566C0>\n"
     ]
    }
   ],
   "source": [
    "print(model_0.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Saving our Pytorch Model\n",
    "from pathlib import Path\n",
    "MODEL_PATH=Path(\"Pytorch_Linear_Regression_Model.pt\")\n",
    "torch.save(model_0,MODEL_PATH)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('weights', tensor([0.6990])), ('bias', tensor([0.3093]))])"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Loading our Pytorch Model\n",
    "loaded_model=torch.load(MODEL_PATH)\n",
    "loaded_model.state_dict()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Putting it all togother"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn \n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.1.2+cu118'"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "## Setup device agnostic code\n",
    "device=\"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create some data using the linear regression formula of y=WX+b+e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight=0.7\n",
    "bias=0.3\n",
    "\n",
    "#Create range values\n",
    "start=0\n",
    "end=1\n",
    "step=0.02\n",
    "\n",
    "# Create X and y(features and lables)\n",
    "X=torch.arange(start,end,step).unsqueeze(dim=1)\n",
    "y=weight*X+bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0000],\n",
      "        [0.0200],\n",
      "        [0.0400],\n",
      "        [0.0600],\n",
      "        [0.0800],\n",
      "        [0.1000],\n",
      "        [0.1200],\n",
      "        [0.1400],\n",
      "        [0.1600],\n",
      "        [0.1800],\n",
      "        [0.2000],\n",
      "        [0.2200],\n",
      "        [0.2400],\n",
      "        [0.2600],\n",
      "        [0.2800],\n",
      "        [0.3000],\n",
      "        [0.3200],\n",
      "        [0.3400],\n",
      "        [0.3600],\n",
      "        [0.3800],\n",
      "        [0.4000],\n",
      "        [0.4200],\n",
      "        [0.4400],\n",
      "        [0.4600],\n",
      "        [0.4800],\n",
      "        [0.5000],\n",
      "        [0.5200],\n",
      "        [0.5400],\n",
      "        [0.5600],\n",
      "        [0.5800],\n",
      "        [0.6000],\n",
      "        [0.6200],\n",
      "        [0.6400],\n",
      "        [0.6600],\n",
      "        [0.6800],\n",
      "        [0.7000],\n",
      "        [0.7200],\n",
      "        [0.7400],\n",
      "        [0.7600],\n",
      "        [0.7800],\n",
      "        [0.8000],\n",
      "        [0.8200],\n",
      "        [0.8400],\n",
      "        [0.8600],\n",
      "        [0.8800],\n",
      "        [0.9000],\n",
      "        [0.9200],\n",
      "        [0.9400],\n",
      "        [0.9600],\n",
      "        [0.9800]])\n"
     ]
    }
   ],
   "source": [
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.3000],\n",
      "        [0.3140],\n",
      "        [0.3280],\n",
      "        [0.3420],\n",
      "        [0.3560],\n",
      "        [0.3700],\n",
      "        [0.3840],\n",
      "        [0.3980],\n",
      "        [0.4120],\n",
      "        [0.4260],\n",
      "        [0.4400],\n",
      "        [0.4540],\n",
      "        [0.4680],\n",
      "        [0.4820],\n",
      "        [0.4960],\n",
      "        [0.5100],\n",
      "        [0.5240],\n",
      "        [0.5380],\n",
      "        [0.5520],\n",
      "        [0.5660],\n",
      "        [0.5800],\n",
      "        [0.5940],\n",
      "        [0.6080],\n",
      "        [0.6220],\n",
      "        [0.6360],\n",
      "        [0.6500],\n",
      "        [0.6640],\n",
      "        [0.6780],\n",
      "        [0.6920],\n",
      "        [0.7060],\n",
      "        [0.7200],\n",
      "        [0.7340],\n",
      "        [0.7480],\n",
      "        [0.7620],\n",
      "        [0.7760],\n",
      "        [0.7900],\n",
      "        [0.8040],\n",
      "        [0.8180],\n",
      "        [0.8320],\n",
      "        [0.8460],\n",
      "        [0.8600],\n",
      "        [0.8740],\n",
      "        [0.8880],\n",
      "        [0.9020],\n",
      "        [0.9160],\n",
      "        [0.9300],\n",
      "        [0.9440],\n",
      "        [0.9580],\n",
      "        [0.9720],\n",
      "        [0.9860]])\n"
     ]
    }
   ],
   "source": [
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data\n",
    "train_split=int(0.8*len(X))\n",
    "X_train,y_train=X[:train_split],y[:train_split]\n",
    "X_test,y_test=X[train_split:],y[train_split:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAzoAAAJGCAYAAACTJvC6AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8g+/7EAAAACXBIWXMAAA9hAAAPYQGoP6dpAABLDElEQVR4nO3df3xT9d3//2caaAqDlvGr/KoU3UTcEBSkA3Qks1o3L06YbqJOQKZuONRd6bwQplLQad01ZWwRf8yhON0GU9Gca/hljpri0Do2kE0U6pTfhRaYmiJKC+n5/pEPqVlbaErbJCeP++2W2xkn5+S8Ek5Zn77feb8clmVZAgAAAAAbyUh0AQAAAADQ3gg6AAAAAGyHoAMAAADAdgg6AAAAAGyHoAMAAADAdgg6AAAAAGyHoAMAAADAdrokuoDWaGho0N69e9WzZ085HI5ElwMAAAAgQSzL0qFDhzRo0CBlZLQ8bpMSQWfv3r3Ky8tLdBkAAAAAksTu3bs1ZMiQFp9PiaDTs2dPSZE3k52dneBqAAAAACRKbW2t8vLyohmhJSkRdI5PV8vOziboAAAAADjpV1pYjAAAAACA7RB0AAAAANgOQQcAAACA7RB0AAAAANgOQQcAAACA7RB0AAAAANhOSiwv3RZHjx5VOBxOdBlAQjmdTnXt2jXRZQAAAHQ62wWd2tpaHTx4UHV1dYkuBUgKLpdLffv2pQcVAABIK3EHnVdffVU/+9nPtGHDBu3bt08vvPCCpkyZcsJzysvLVVxcrLffflt5eXm68847dd1117Wx5JbV1taqqqpKPXr0UN++fdW1a9eTNhIC7MqyLB09elShUEhVVVWSRNgBAABpI+6gc/jwYY0aNUrf/e53dfnll5/0+O3bt+uyyy7TrFmz9Nvf/lZlZWW64YYbNHDgQBUVFbWp6JYcPHhQPXr00JAhQwg4gKRu3bqpZ8+e2rNnjw4ePEjQAQAAaSPuoPP1r39dX//611t9/KOPPqphw4bpwQcflCSNGDFC69at089//vN2DTpHjx5VXV2d+vbtS8gBPsPhcCgnJ0dVVVU6evQo39kBAABpocNXXauoqFBhYWHMvqKiIlVUVLR4Tl1dnWpra2MeJ3N84QF+iQOaOv5zwQIdAAAgXXR40KmurlZubm7MvtzcXNXW1urTTz9t9pzS0lLl5OREH3l5ea2+HqM5QFP8XAAAgHSTlH105s2bp1AoFH3s3r070SUBAAAASCEdvrz0gAEDVFNTE7OvpqZG2dnZ6tatW7PnuFwuuVyuji4NAAAAgE11+IjO+PHjVVZWFrPvz3/+s8aPH9/Rl0YncTgccrvdp/Qa5eXlcjgcWrBgQbvUBAAAgPQWd9D5+OOPtWnTJm3atElSZPnoTZs2adeuXZIi086mT58ePX7WrFnatm2b5syZo61bt+rhhx/WH/7wB/l8vvZ5B5AUCRvxPHBy+fn5MZ+Zy+VSv379NG7cOM2ePVvr1q1rl+sQ8gAAANpf3FPX/v73v8vj8UT/XFxcLEmaMWOGli1bpn379kVDjyQNGzZMq1atks/n0y9+8QsNGTJEv/71r9u9h066KykpabJv8eLFCoVCzT7XnrZs2aLu3buf0muMGzdOW7ZsUd++fdupqvbhdDp15513SpKOHTumDz/8UG+99ZYee+wxPfzww5o8ebKeeuopff7zn09wpQAAAPgsh2VZVqKLOJna2lrl5OQoFAq12PDwyJEj2r59u4YNG6asrKxOrjA55efna+fOnUqBv+KklJ+fr+rqah05cqTJczt37tT111+vsrIyTZo0Sa+88ooyMto2E7S8vFwej0clJSUdNqrDzwcAALCL1mQDKUlXXUPH2bFjhxwOh6677jpt2bJF3/zmN9WnTx85HA7t2LFDkvTCCy/o6quv1he+8AV1795dOTk5uvDCC/X88883+5rNfUfnuuuuk8Ph0Pbt2/XLX/5SZ511llwul4YOHaqFCxeqoaEh5viWpm/l5+crPz9fH3/8sX74wx9q0KBBcrlcOuecc/Tcc8+1+B6nTp2q3r17q0ePHpo0aZJeffVVLViwQA6HQ+Xl5W356GIMHTpU//d//6cRI0Zo7dq1TWp54okn5PV6lZ+fr6ysLPXu3VtFRUUKBoMxxy1YsCA6Qrpw4cKYqXLH/z7effddzZkzR+edd5769OmjrKwsnXnmmZo7d64+/vjjU34vAAAAdtThq64hOb333nv6yle+opEjR+q6667Tv//9b2VmZkqKfM8qMzNTF1xwgQYOHKgDBw7INE1961vf0i9/+Uvdcsstrb7O//zP/2jt2rX6r//6LxUVFenFF1/UggULVF9fr3vvvbdVr3H06FFdcskl+vDDD3XFFVfok08+0fLly3XllVdq9erVuuSSS6LHVlVVacKECdq3b58uvfRSnXvuuaqsrNTFF1+sr33ta/F9SCfRrVs33Xbbbbr++uu1YsUKXXnlldHnZs+erVGjRqmwsFD9+vVTVVWVXnzxRRUWFmrlypXyer2SJLfbrR07duipp57SpEmTYgJjr169JEkrV67U0qVL5fF45Ha71dDQoDfeeEM//elPtXbtWr366qs0ygUAAB3GrDQV3B6UZ5hHxnAj0eW0npUCQqGQJckKhUItHvPpp59a77zzjvXpp592YmXJbejQodZ//hVv377dkmRJsubPn9/see+//36TfYcOHbJGjhxp5eTkWIcPH455TpI1adKkmH0zZsywJFnDhg2z9u7dG91/4MABq1evXlbPnj2turq66P5gMGhJskpKSpp9D16vN+b4NWvWWJKsoqKimOOvvfZaS5J17733xuxfunRp9H0Hg8Fm3/d/Gjp0qOVyuU54zPvvv29JsvLy8mL2b9u2rcmxe/futQYNGmR98YtfjNnf0ns/bs+ePTHv/biFCxdakqxnnnnmJO+Enw8AANA2ga0BSwtkORc6LS2QFdgaSHRJrcoGlmVZTF1LUwMGDNAdd9zR7HOnn356k309evTQddddp1AopL/97W+tvs5dd92lgQMHRv/ct29feb1eHTp0SJWVla1+nZ///OfRESdJuuiiizR06NCYWurq6vTss8+qf//++tGPfhRz/syZMzV8+PBWX6+1Bg0aJEk6ePBgzP5hw4Y1OXbgwIG64oor9K9//Us7d+5s9TUGDx4c896Pu/nmmyVJa9asiadkAACAVgtuD8rpcCpsheV0OFW+ozzRJbUaQaeNTFPy+SLbVDRq1Khmf3mWpP3796u4uFgjRoxQ9+7do98ZOR4e9u7d2+rrjBkzpsm+IUOGSJI++uijVr1Gr169mg0OQ4YMiXmNyspK1dXVaezYsU0azjocDk2YMKHVdZ+qbdu26cYbb9QZZ5yhrKys6Gfo9/slxfcZWpalJ554Ql/96lfVu3dvOZ1OORwO9enTJ+7XAgAAiIdnmCcacsJWWO58d6JLajW+o9MGpil5vZLTKS1eLAUCkpFC0xUlKTc3t9n9H3zwgc4//3zt2rVLEydOVGFhoXr16iWn06lNmzYpEAiorq6u1ddpbiWMLl0it104HG7Va+Tk5DS7v0uXLjGLGtTW1kqS+vfv3+zxLb3nU3E8ZPTr1y+677333tO4ceNUW1srj8ejyZMnKzs7WxkZGSovL9fatWvj+gxvvfVWPfTQQ8rLy5NhGBo4cGA0yC1cuDCu1wIAAIiHMdxQ4KqAyneUy53vTqnv6BB02iAYjISccDiyLS9PvaDTUtPQpUuXateuXbrnnnui/WOOu//++xUIBDqjvDY5Hqr279/f7PM1NTXtfs3jK7idf/750X0///nP9eGHH+rpp5/WtddeG3P8rFmztHbt2la//v79+7VkyRKdc845qqioiOlXVF1drYULF57aGwAAADgJY7iRUgHnOKautYHH0xhywmHpP1ZWTmnvv/++JEVXBfusv/zlL51dTlyGDx8ul8ulDRs2NBnlsCxLFRUV7Xq9Tz/9VA8++KAk6eqrr47ub+kztCxLr732WpPXcTqdkpof4dq2bZssy1JhYWGTpqzJ/vcBAACQSASdNjCMyHS1W29NzWlrJzJ06FBJ0rp162L2/+53v9NLL72UiJJazeVy6Vvf+pZqamq0ePHimOd+85vfaOvWre12rV27dmny5Ml655135PF4dPnll0efa+kzvP/++7V58+Ymr9W7d29J0u7du5s8d/y1Xn/99Zhpenv27NG8efNO/Y0AAADYFFPX2sgw7BVwjps2bZp++tOf6pZbblEwGNTQoUP1j3/8Q2VlZbr88su1cuXKRJd4QqWlpVqzZo3mzp2rtWvXRvvo/PGPf9Sll16q1atXKyOj9fn+2LFj0Sam4XBYH330kf75z3/qtddeUzgcltfr1bJly2KmAs6aNUtPPvmkrrjiCl155ZXq06eP3njjDW3cuFGXXXaZVq1aFXONs846S4MGDdLy5cvlcrk0ZMgQORwO3XLLLdGV2p5//nmNHTtWF110kWpqavTHP/5RF110UXT0CAAAALEIOogxZMgQrV27VnPmzNGaNWt07NgxnXfeeXr55Ze1e/fupA86eXl5qqio0O23366XX35Za9eu1ZgxY/Tyyy/r2WefldT8AgktCYfD0e/BZGZmKjs7W8OGDdP3v/99XXPNNZo4cWKTc84991y9/PLLuvPOO7Vy5Uo5nU5NmDBBr732mkzTbBJ0nE6nVq5cqdtvv12///3vdejQIUnStddeq5ycHC1btkz5+fl6/vnn5ff7ddppp6m4uFi33367nnvuubZ+VAAAALbmsCzLSnQRJ1NbW6ucnByFQqEWf0k9cuSItm/frmHDhikrK6uTK0QquOCCC1RRUaFQKKQePXokupxOxc8HAAAwK00FtwflGeZJycUFjmtNNpD4jg5saN++fU32PfPMM3rttddUWFiYdiEHAADArDTlXe6Vf71f3uVemZUp2gwyDkxdg+18+ctf1rnnnquzzz472v+nvLxcPXv21AMPPJDo8gAAADpdcHsw2vTT6XCqfEd5So/qtAYjOrCdWbNmaf/+/frNb36jhx56SJWVlbrmmmu0fv16jRw5MtHlAQAAdDrPME805IStsNz57kSX1OH4jg6QBvj5AAAAZqWp8h3lcue7U3o0p7Xf0WHqGgAAAJAGjOFGSgeceDF1DQAAAIDtEHQAAAAA2A5BBwAAAIDtEHQAAAAA2A5BBwAAAEghZqUp32pfWjT9PBUEHQAAACBFmJWmvMu98q/3y7vcS9g5AYIOAAAAkCKC24PRpp9Oh1PlO8oTXVLSIugAAAAAKcIzzBMNOWErLHe+O9ElJS0ahqJTuN1urV27VpZlJboUAACAlGUMNxS4KqDyHeVy57vTqgFovBjRsQmHwxHXo70tWLBADodD5eXl7f7aHWHZsmUxn0dGRoays7M1bNgweb1e+f1+ffDBB+1yLbfb3SGfOQAASE/GcEOLihYRck6CER2bKCkpabJv8eLFCoVCzT7X2X7zm9/ok08+SXQZTVx00UW64IILJEkff/yxqqqq9Je//EWmaaqkpESPPfaYvv3tbye4SgAAAMSLoGMTCxYsaLJv2bJlCoVCzT7X2U477bREl9CswsJCzZ07N2ZfOBzWU089pZtvvllXX321cnJydMkllySoQgAAALQFU9fSUH19vRYtWqTzzjtPn/vc59SzZ09deOGFMs2myxOGQiHNnz9fZ599tnr06KHs7Gx94Qtf0IwZM7Rz505JkalZCxculCR5PJ7odLD8/Pzo6zQ3fev49LFly5bp5Zdf1oQJE9S9e3f16dNHM2bM0L///e9m63/sscf0pS99SVlZWcrLy9OcOXN05MgRORwOud3uU/58nE6nvvvd7+qRRx5ROBxWcXFxzHeL3n33Xc2ZM0fnnXee+vTpo6ysLJ155pmaO3euPv7445jXcjgcWrt2bfR/H39cd9110WOeeOIJeb1e5efnKysrS71791ZRUZGCweApvxcAAIB0xYhOmqmrq9Oll16q8vJyjR49Wtdff72OHj2qVatWRb+bcvPNN0uSLMtSUVGR/vrXv2rixIm69NJLlZGRoZ07d8o0TU2bNk1Dhw6N/tK+du1azZgxIxpwevXq1aqaTNPUqlWrNHnyZE2YMEGvvvqqfvOb3+j999/XunXrYo6dP3++7rnnHuXm5urGG29U165d9Yc//EFbt25tr48oatq0aSopKdHbb7+tzZs3a+TIkZKklStXaunSpfJ4PHK73WpoaNAbb7yhn/70p1q7dq1effVVde3aVVJkSuGyZcu0c+fOmCmEo0ePjv7v2bNna9SoUSosLFS/fv1UVVWlF198UYWFhVq5cqW8Xm+7vzcAAADbs1JAKBSyJFmhUKjFYz799FPrnXfesT799NNOrCy5DR061PrPv+If//jHliTrrrvushoaGqL7a2trrbFjx1qZmZlWVVWVZVmW9c9//tOSZE2ZMqXJax85csQ6dOhQ9M8lJSWWJCsYDDZby6RJk5rU8uSTT1qSrC5duljr1q2L7j927JjldrstSVZFRUV0f2VlpeV0Oq3BgwdbNTU1MbWfffbZliRr0qRJJ/9gPnPt0tLSEx43bdo0S5K1dOnS6L49e/ZYdXV1TY5duHChJcl65plnTvreP2vbtm1N9u3du9caNGiQ9cUvfvFkb6VV+PkAACC5BLYGrP/+//7bCmwNJLqUlNOabGBZlsXUtTYyK035VvtSqhttQ0ODHnnkEZ1xxhlauHBhzFSynj17av78+aqvr9fKlStjzuvWrVuT13K5XOrRo0e71HXNNddo4sSJ0T87nU7NmDFDkvS3v/0tuv/3v/+9wuGwfvSjH6l///4xtd95553tUst/GjRokCTp4MGD0X2DBw9WZmZmk2OPj4StWbMmrmsMGzasyb6BAwfqiiuu0L/+9a/oFEEAAGAPZqUp73Kv/Ov98i73ptTvk6mEqWttcPzmdDqcWvzXxQpcFUiJ5f0qKyv14YcfatCgQdHv1HzWgQMHJCk6DWzEiBE655xz9Pvf/1579uzRlClT5Ha7NXr0aGVktF9GHjNmTJN9Q4YMkSR99NFH0X3/+Mc/JCm6StpnfTYodTTLsvTkk09q2bJl2rx5s0KhkBoaGqLP7927N67X27Ztm0pLS/XKK6+oqqpKdXV1Mc/v3btXQ4cObZfaAQBA4gW3B6MNP50Op8p3lKfE75KphqDTBql6cx7vC/P222/r7bffbvG4w4cPS5K6dOmiV155RQsWLNDzzz+vH/3oR5Kkfv366eabb9Ydd9whp9N5ynVlZ2c32delS+TWDIfD0X21tbWSFDOac1xubu4p19Gc46GlX79+0X233nqrHnroIeXl5ckwDA0cOFAul0uStHDhwiZB5UTee+89jRs3TrW1tfJ4PJo8ebKys7OVkZGh8vJyrV27Nq7XAwAAyc8zzKPFf10c/X3Sne9OdEm2RNBpg1S9OY8HiiuuuELPPfdcq87p06eP/H6/fvnLX2rr1q165ZVX5Pf7VVJSoq5du2revHkdWXKM4/Xv37+/yQhHTU1Nu1+voaFBr776qiTp/PPPj157yZIlOuecc1RRUaHu3btHj6+urm52pOxEfv7zn+vDDz/U008/rWuvvTbmuVmzZkVXbAMAAPZhDDcUuCqg8h3lcue7U+I/mKcivqPTBsdvzlsLbk2ZaWtSZCpadna2/v73v+vo0aNxnetwODRixAjNnj1bf/7znyUpZjnq4yM7nx2BaW+jRo2SJL322mtNnnv99dfb/XpPP/20du7cqZEjR+pLX/qSpMg0M8uyVFhYGBNyJOkvf/lLs69zos/m/fffl6QmK6tZltXs+wQAAPZgDDe0qGhRyvwemYoIOm2Uijdnly5ddNNNN2nnzp267bbbmg07mzdv1v79+yVJO3bs0I4dO5occ3z0JCsrK7qvd+/ekqTdu3d3QOURV111lTIyMvTggw/GLA5w+PBh3Xvvve12nXA4rCeffFI33XSTnE6nFi1aFF244fhI0uuvvx7zvZw9e/a0OLp1os/m+Ov95zLa999/vzZv3nzqbwYAACBNMXUtzSxcuFAbN27UL3/5S61atUpf/epX1b9/f1VVVemtt97SP/7xD1VUVKh///7atGmTLr/8co0bN05nn322BgwYEO3xkpGRIZ/PF33d441Cf/zjH+vtt99WTk6OevXqFV2JrD0MHz5cc+fO1X333aeRI0fqyiuvVJcuXbRy5UqNHDlSmzdvjnuRhDVr1ujIkSOSpE8++UR79uzRq6++qqqqKvXu3VtPP/20CgsLo8cfXw3t+eef19ixY3XRRReppqZGf/zjH3XRRRdFR2g+62tf+5qee+45XXHFFfr617+urKwsjRo1SpMnT9asWbP05JNP6oorrtCVV16pPn366I033tDGjRt12WWXadWqVaf2oQEAAKSrzljr+lTRR6dtmuujY1mRPjWPPfaYNXHiRCs7O9tyuVzWaaedZl166aXWI488Yn388ceWZVnW7t27rblz51pf+cpXrP79+1uZmZnWaaedZl1++eUx/W2OW7ZsmTVy5EjL5XJZkqyhQ4dGnztRH50nn3yyyWsFg0FLklVSUtLkuYcfftgaMWKElZmZaQ0ZMsS67bbbrN27d1uSLK/X26rP5vi1jz8cDofVo0cPKz8/35o8ebLl9/utDz74oNlzDx06ZP3oRz+y8vPzLZfLZX3xi1+07rnnHqu+vr7ZXj5Hjx615syZY5122mlWly5dLEnWjBkzYt7rxIkTrZ49e1q9evWyvvGNb1gbNmw4aW+iePDzAQAA7KK1fXQclmVZiQhY8aitrVVOTo5CoVCzK3RJ0pEjR7R9+3YNGzYsZkoV0sOaNWt08cUXa86cOfrpT3+a6HKSDj8fAADALlqTDSS+o4MUc+DAgSZf6v/oo4+i34+ZMmVKAqoCAADpKhWbyKcLvqODlPLb3/5WDzzwgL72ta9p0KBB2rdvn1avXq39+/fruuuu0/jx4xNdIgAASBOp2kQ+XRB0kFImTJigMWPGaM2aNfrggw/kdDo1YsQI3XXXXfrBD36Q6PIAAEAaSdUm8umCoIOUMm7cOAUCgUSXAQAAkLJN5NMFQQcAAABog+NN5Mt3lMud72Y0J8kQdAAAAIA2MoYbBJwkZbtV11JgtWyg0/FzAQAA0o1tgo7T6ZQkHT16NMGVAMnn+M/F8Z8TAAAAu7NN0OnatatcLpdCoRD/9Rr4DMuyFAqF5HK51LVr10SXAwAA0Cls9R2dvn37qqqqSnv27FFOTo66du0qh8OR6LKAhLAsS0ePHlUoFNLHH3+swYMHJ7okAACATmOroJOdnS1JOnjwoKqqqhJcDZAcXC6XBg8eHP35AAAATZmVpoLbg/IM87C4gE04rBSY51VbW6ucnByFQqFW/7J29OhRhcPhDq4MSG5Op5PpagAAnIRZacq73BvthxO4KkDYSWKtzQa2GtH5rK5du/ILHgAAAE4quD0YDTlOh1PlO8oJOjZgm8UIAAAAgLbwDPNEQ07YCsud7050SWgHth3RAQAAAFrDGG4ocFVA5TvK5c53M5pjE7b9jg4AAAAA+2ltNmDqGgAAAADbIegAAAAAsB2CDgAAAADbaVPQWbJkifLz85WVlaWCggKtX7++xWOPHj2qu+++W2eccYaysrI0atQorV69us0FAwAAAMDJxB10VqxYoeLiYpWUlGjjxo0aNWqUioqKtH///maPv/POO/XYY4/J7/frnXfe0axZs/TNb35Tb7755ikXDwAAABxnVpryrfbJrDQTXQqSQNyrrhUUFOj888/XQw89JElqaGhQXl6ebrnlFs2dO7fJ8YMGDdIdd9yh2bNnR/ddccUV6tatm5555plWXZNV1wAAAHAiZqUp73JvtBdO4KoAy0TbVIesulZfX68NGzaosLCw8QUyMlRYWKiKiopmz6mrq1NWVlbMvm7dumndunUtXqeurk61tbUxDwAAAKAlwe3BaMhxOpwq31Ge6JKQYHEFnYMHDyocDis3Nzdmf25urqqrq5s9p6ioSIsWLdK//vUvNTQ06M9//rNWrlypffv2tXid0tJS5eTkRB95eXnxlAkAAIA04xnmiYacsBWWO9+d6JKQYB2+6tovfvELffGLX9RZZ52lzMxM3XzzzZo5c6YyMlq+9Lx58xQKhaKP3bt3d3SZAAAASGHGcEOBqwK6teBWpq1BktQlnoP79u0rp9OpmpqamP01NTUaMGBAs+f069dPL774oo4cOaJ///vfGjRokObOnavTTz+9xeu4XC65XK54SgMAAECaM4YbBBxExTWik5mZqTFjxqisrCy6r6GhQWVlZRo/fvwJz83KytLgwYN17NgxPf/88/J6vW2rGAAAAABOIq4RHUkqLi7WjBkzNHbsWI0bN06LFy/W4cOHNXPmTEnS9OnTNXjwYJWWlkqS/vrXv6qqqkqjR49WVVWVFixYoIaGBs2ZM6d93wkAAAAA/D9xB52pU6fqwIEDmj9/vqqrqzV69GitXr06ukDBrl27Yr5/c+TIEd15553atm2bevTooW984xt6+umn1atXr3Z7EwAAAADwWXH30UkE+ugAAAAAkDqojw4AAADQ0cxKU77VPpmVZqJLQQoj6AAAACBpmJWmvMu98q/3y7vcS9hBmxF0AAAAkDSC24PRpp9Oh1PlO8oTXRJSFEEHAAAAScMzzBMNOWErLHe+O9ElIUXFveoaAAAA0FGM4YYCVwVUvqNc7nw3DUDRZqy6BgAAACBlsOoaAAAAgLRF0AEAAABgOwQdAAAAALZD0AEAAABgOwQdAAAAtDuz0pRvtY+Gn0gYgg4AAADalVlpyrvcK/96v7zLvYQdJARBBwAAAO0quD0YbfjpdDhVvqM80SUhDRF0AAAA0K48wzzRkBO2wnLnuxNdEtJQl0QXAAAAAHsxhhsKXBVQ+Y5yufPdMoYbiS4JachhWZaV6CJOprXdTwEAAADYW2uzAVPXAAAAANgOQQcAAACA7RB0AAAAANgOQQcAAACA7RB0AAAA0CKz0pRvtY+mn0g5BB0AAAA0y6w05V3ulX+9X97lXsIOUgpBBwAAAM0Kbg9Gm346HU6V7yhPdElAqxF0AAAA0CzPME805IStsNz57kSXBLRal0QXAAAAgORkDDcUuCqg8h3lcue7ZQw3El0S0GoOy7KsRBdxMq3tfgoAAADA3lqbDZi6BgAAAMB2CDoAAAAAbIegAwAAAMB2CDoAAAAAbIegAwAAkAZMU/L5IlsgHRB0AAAAbM40Ja9X8vsjW8IO0gFBBwAAwOaCQcnplMLhyLa8PNEVAR2PoAMAAGBzHk9jyAmHJbc70RUBHa9LogsAAABAxzIMKRCIjOS43ZE/A3ZH0AEAAEgDhkHAQXph6hoAAAAA2yHoAAAAALAdgg4AAAAA2yHoAAAAALAdgg4AAECKME3J56PhJ9AaBB0AAIAUYJqS1yv5/ZEtYQc4MYIOAABACggGGxt+Op2RnjgAWkbQAQAASAEeT2PICYcjjT8BtIyGoQAAACnAMKRAIDKS43bT/BM4GYIOAABAijAMAg7QWkxdAwAAAGA7BB0AAAAAtkPQAQAAAGA7BB0AAAAAtkPQAQAA6GSmKfl8NP0EOhJBBwAAoBOZpuT1Sn5/ZEvYAToGQQcAAKATBYONTT+dzkhfHADtj6ADAADQiTyexpATDkeafwJofzQMBQAA6ESGIQUCkZEct5sGoEBHIegAAAB0MsMg4AAdjalrAAAAAGyHoAMAAADAdgg6AAAAAGyHoAMAAADAdgg6AAAAbWSaks9H008gGbUp6CxZskT5+fnKyspSQUGB1q9ff8LjFy9erOHDh6tbt27Ky8uTz+fTkSNH2lQwAABAMjBNyeuV/P7IlrADJJe4g86KFStUXFyskpISbdy4UaNGjVJRUZH279/f7PG/+93vNHfuXJWUlGjLli1aunSpVqxYoR//+MenXDwAAECiBIONTT+dzkhfHADJI+6gs2jRIt14442aOXOmzj77bD366KPq3r27nnjiiWaPf/311zVx4kRdc801ys/P1yWXXKKrr776pKNAAAAAyczjaQw54XCk+SeA5BFX0Kmvr9eGDRtUWFjY+AIZGSosLFRFRUWz50yYMEEbNmyIBptt27bppZde0je+8Y0Wr1NXV6fa2tqYBwAAQDIxDCkQkG69NbKlASiQXLrEc/DBgwcVDoeVm5sbsz83N1dbt25t9pxrrrlGBw8e1AUXXCDLsnTs2DHNmjXrhFPXSktLtXDhwnhKAwAA6HSGQcABklWHr7pWXl6u++67Tw8//LA2btyolStXatWqVbrnnntaPGfevHkKhULRx+7duzu6TAAAAAA2EteITt++feV0OlVTUxOzv6amRgMGDGj2nLvuukvTpk3TDTfcIEkaOXKkDh8+rO9973u64447lJHRNGu5XC65XK54SgMAAACAqLhGdDIzMzVmzBiVlZVF9zU0NKisrEzjx49v9pxPPvmkSZhxOp2SJMuy4q0XAAAAAE4qrhEdSSouLtaMGTM0duxYjRs3TosXL9bhw4c1c+ZMSdL06dM1ePBglZaWSpImT56sRYsW6dxzz1VBQYHee+893XXXXZo8eXI08AAAAABAe4o76EydOlUHDhzQ/PnzVV1drdGjR2v16tXRBQp27doVM4Jz5513yuFw6M4771RVVZX69eunyZMn6957722/dwEAANBGphnpiePxsLAAYCcOKwXmj9XW1ionJ0ehUEjZ2dmJLgcAANiEaUpeb2MvHJaJBpJfa7NBh6+6BgAAkKyCwcaQ43RK5eWJrghAeyHoAACAtOXxNIaccFhyuxNdEYD2Evd3dAAAAOzCMCLT1crLIyGHaWuAfRB0AABAWjMMAg5gR0xdAwAAAGA7BB0AAAAAtkPQAQAAAGA7BB0AAAAAtkPQAQAAtmCaks8X2QIAQQcAAKQ805S8Xsnvj2wJOwAIOgAAIOUFg41NP53OSF8cAOmNoAMAAFKex9MYcsLhSPNPAOmNhqEAACDlGYYUCERGctxuGoACIOgAAACbMAwCDoBGTF0DAAAAYDsEHQAAAAC2Q9ABAAAAYDsEHQAAAAC2Q9ABAABJwzQln4+GnwBOHUEHAAAkBdOUvF7J749sCTsATgVBBwAAJIVgsLHhp9MZ6YkDAG1F0AEAAEnB42kMOeFwpPEnALQVDUMBAEBSMAwpEIiM5LjdNP8EcGoIOgAAIGkYBgEHQPtg6hoAAAAA2yHoAAAAALAdgg4AAAAA2yHoAAAAALAdgg4AAGh3pin5fDT9BJA4BB0AANCuTFPyeiW/P7Il7ABIBIIOAABoV8FgY9NPpzPSFwcAOhtBBwAAtCuPpzHkhMOR5p8A0NloGAoAANqVYUiBQGQkx+2mASiAxCDoAACAdmcYBBwAicXUNQAAAAC2Q9ABAAAAYDsEHQAAAAC2Q9ABAAAAYDsEHQAA0CLTlHw+mn4CSD0EHQAA0CzTlLxeye+PbAk7AFIJQQcAADQrGGxs+ul0RvriAECqIOgAAIBmeTyNISccjjT/BIBUQcNQAADQLMOQAoHISI7bTQNQAKmFoAMAAFpkGAQcAKmJqWsAAAAAbIegAwAAAMB2CDoAAAAAbIegAwAAAMB2CDoAANicaUo+Hw0/AaQXgg4AADZmmpLXK/n9kS1hB0C6IOgAAGBjwWBjw0+nM9ITBwDSAUEHAAAb83gaQ044HGn8CQDpgIahAADYmGFIgUBkJMftpvkngPRB0AEAwOYMg4ADIP0wdQ0AAACA7RB0AAAAANgOQQcAAACA7RB0AAAAANgOQQcAgBRhmpLPR9NPAGgNgg4AACnANCWvV/L7I1vCDgCcWJuCzpIlS5Sfn6+srCwVFBRo/fr1LR7rdrvlcDiaPC677LI2Fw0AQLoJBhubfjqdkb44AICWxR10VqxYoeLiYpWUlGjjxo0aNWqUioqKtH///maPX7lypfbt2xd9bN68WU6nU9/+9rdPuXgAANKFx9MYcsLhSPNPAEDLHJZlWfGcUFBQoPPPP18PPfSQJKmhoUF5eXm65ZZbNHfu3JOev3jxYs2fP1/79u3T5z73uVZds7a2Vjk5OQqFQsrOzo6nXAAAbMM0IyM5bjcNQAGkr9Zmgy7xvGh9fb02bNigefPmRfdlZGSosLBQFRUVrXqNpUuX6qqrrjphyKmrq1NdXV30z7W1tfGUCQCALRkGAQcAWiuuqWsHDx5UOBxWbm5uzP7c3FxVV1ef9Pz169dr8+bNuuGGG054XGlpqXJycqKPvLy8eMoEAAAAkOY6ddW1pUuXauTIkRo3btwJj5s3b55CoVD0sXv37k6qEAAAAIAdxDV1rW/fvnI6naqpqYnZX1NTowEDBpzw3MOHD2v58uW6++67T3odl8sll8sVT2kAAAAAEBXXiE5mZqbGjBmjsrKy6L6GhgaVlZVp/PjxJzz32WefVV1dna699tq2VQoAAAAArRT31LXi4mI9/vjjeuqpp7RlyxbddNNNOnz4sGbOnClJmj59esxiBcctXbpUU6ZMUZ8+fU69agAAUphpSj4fTT8BoCPFNXVNkqZOnaoDBw5o/vz5qq6u1ujRo7V69eroAgW7du1SRkZsfqqsrNS6dev08ssvt0/VAACkKNOUvN5IP5zFi6VAgJXUAKAjxN1HJxHoowMAsAufT/L7G5t/3nqrtGhRoqsCgNTR2mzQqauuAQCQ7jyexpATDkeafwIA2l/cU9cAAEDbGUZkulp5eSTkMG0NADoGQQcAgE5mGAQcAOhoTF0DAAAAYDsEHQAAAAC2Q9ABAAAAYDsEHQAAAAC2Q9ABAKANTDPSE8c0E10JAKA5BB0AAOJkmpLXG2n86fUSdgAgGRF0AACIUzDY2PDT6Yz0xAEAJBeCDgAAcfJ4GkNOOBxp/AkASC40DAUAIE6GIQUCkZEct5vmnwCQjAg6AAC0gWEQcAAgmTF1DQAAAIDtEHQAAAAA2A5BBwAAAIDtEHQAAAAA2A5BBwCQ1kxT8vlo+gkAdkPQAQCkLdOUvF7J749sCTsAYB8EHQBA2goGG5t+Op2RvjgAAHsg6AAA0pbH0xhywuFI808AgD3QMBQAkLYMQwoEIiM5bjcNQAHATgg6AIC0ZhgEHACwI6auAQAAALAdgg4AAAAA2yHoAAAAALAdgg4AAAAA2yHoAABSnmlKPh8NPwEAjQg6AICUZpqS1yv5/ZEtYQcAIBF0AAApLhhsbPjpdEZ64gAAQNABAKQ0j6cx5ITDkcafAADQMBQAkNIMQwoEIiM5bjfNPwEAEQQdAEDKMwwCDgAgFlPXAAAAANgOQQcAAACA7RB0AAAAANgOQQcAAACA7RB0AABJwzQln4+mnwCAU0fQAQAkBdOUvF7J749sCTsAgFNB0AEAJIVgsLHpp9MZ6YsDAEBbEXQAAEnB42kMOeFwpPknAABtRcNQAEBSMAwpEIiM5LjdNAAFAJwagg4AIGkYBgEHANA+mLoGAAAAwHYIOgAAAABsh6ADAAAAwHYIOgAAAABsh6ADAGh3pin5fDT9BAAkDkEHANCuTFPyeiW/P7Il7AAAEoGgAwBoV8FgY9NPpzPSFwcAgM5G0AEAtCuPpzHkhMOR5p8AAHQ2GoYCANqVYUiBQGQkx+2mASgAIDEIOgCAdmcYBBwAQGIxdQ0AAACA7RB0AAAAANgOQQcAAACA7RB0AAAAANgOQQcA0CzTlHw+Gn4CAFITQQcA0IRpSl6v5PdHtoQdAECqIegAAJoIBhsbfjqdkZ44AACkEoIOAKAJj6cx5ITDkcafAACkkjYFnSVLlig/P19ZWVkqKCjQ+vXrT3j8Rx99pNmzZ2vgwIFyuVw688wz9dJLL7WpYABAxzMMKRCQbr01sqX5JwAg1XSJ94QVK1aouLhYjz76qAoKCrR48WIVFRWpsrJS/fv3b3J8fX29Lr74YvXv31/PPfecBg8erJ07d6pXr17tUT8AoIMYBgEHAJC6HJZlWfGcUFBQoPPPP18PPfSQJKmhoUF5eXm65ZZbNHfu3CbHP/roo/rZz36mrVu3qmvXrq26Rl1dnerq6qJ/rq2tVV5enkKhkLKzs+MpFwAAAICN1NbWKicn56TZIK6pa/X19dqwYYMKCwsbXyAjQ4WFhaqoqGj2HNM0NX78eM2ePVu5ubn68pe/rPvuu0/hcLjF65SWlionJyf6yMvLi6dMAAAAAGkurqBz8OBBhcNh5ebmxuzPzc1VdXV1s+ds27ZNzz33nMLhsF566SXdddddevDBB/WTn/ykxevMmzdPoVAo+ti9e3c8ZQIAAABIc3F/RydeDQ0N6t+/v371q1/J6XRqzJgxqqqq0s9+9jOVlJQ0e47L5ZLL5ero0gAAAADYVFxBp2/fvnI6naqpqYnZX1NTowEDBjR7zsCBA9W1a1c5nc7ovhEjRqi6ulr19fXKzMxsQ9kAgNYyzUhfHI+HxQUAAOkjrqlrmZmZGjNmjMrKyqL7GhoaVFZWpvHjxzd7zsSJE/Xee++poaEhuu/dd9/VwIEDCTkA0MFMU/J6Jb8/sjXNRFcEAEDniLuPTnFxsR5//HE99dRT2rJli2666SYdPnxYM2fOlCRNnz5d8+bNix5/00036YMPPtAPf/hDvfvuu1q1apXuu+8+zZ49u/3eBQCgWcFgY9NPp1MqL090RQAAdI64v6MzdepUHThwQPPnz1d1dbVGjx6t1atXRxco2LVrlzIyGvNTXl6e/vSnP8nn8+mcc87R4MGD9cMf/lC33357+70LAECzPB5p8eLGsON2J7oiAAA6R9x9dBKhtWtlAwCaMs3ISI7bzXd0AACpr7XZoMNXXQMAJJZhEHAAAOkn7u/oAAAAAECyI+gAAAAAsB2CDgAAAADbIegAAAAAsB2CDgCkCNOUfD6afgIA0BoEHQBIAaYpeb2S3x/ZEnYAADgxgg4ApIBgsLHpp9MZ6YsDAABaRtABgBTg8TSGnHA40vwTAAC0jIahAJACDEMKBCIjOW43DUABADgZgg4ApAjDIOAAANBaTF0DAAAAYDsEHQAAAAC2Q9ABAAAAYDsEHQAAAAC2Q9ABgE5kmpLPR8NPAAA6GkEHADqJaUper+T3R7aEHQAAOg5BBwA6STDY2PDT6Yz0xAEAAB2DoAMAncTjaQw54XCk8ScAAOgYNAwFgE5iGFIgEBnJcbtp/gkAQEci6ABAJzIMAg4AAJ2BqWsAAAAAbIegAwAAAMB2CDoAAAAAbIegAwAAAMB2CDoA0AamKfl8NP0EACBZEXQAIE6mKXm9kt8f2RJ2AABIPgQdAIhTMNjY9NPpjPTFAQAAyYWgAwBx8ngaQ044HGn+CQAAkgsNQwEgToYhBQKRkRy3mwagAAAkI4IOALSBYRBwAABIZkxdAwAAAGA7BB0AAAAAtkPQAQAAAGA7BB0AAAAAtkPQAZC2TFPy+Wj4CQCAHRF0AKQl05S8Xsnvj2wJOwAA2AtBB0BaCgYbG346nZGeOAAAwD4IOgDSksfTGHLC4UjjTwAAYB80DAWQlgxDCgQiIzluN80/AQCwG4IOgLRlGAQcAADsiqlrAAAAAGyHoAMAAADAdgg6AAAAAGyHoAMAAADAdgg6AFKeaUo+H00/AQBAI4IOgJRmmpLXK/n9kS1hBwAASAQdACkuGGxs+ul0RvriAAAAEHQApDSPpzHkhMOR5p8AAAA0DAWQ0gxDCgQiIzluNw1AAQBABEEHQMozDAIOAACIxdQ1AAAAALZD0AEAAABgOwQdAAAAALZD0AEAAABgOwQdAEnDNCWfj6afAADg1BF0ACQF05S8Xsnvj2wJOwAA4FQQdAAkhWCwsemn0xnpiwMAANBWBB0AScHjaQw54XCk+ScAAEBb0TAUQFIwDCkQiIzkuN00AAUAAKemTSM6S5YsUX5+vrKyslRQUKD169e3eOyyZcvkcDhiHllZWW0uGIB9GYa0aBEhBwAAnLq4g86KFStUXFyskpISbdy4UaNGjVJRUZH279/f4jnZ2dnat29f9LFz585TKhoAAAAATiTuoLNo0SLdeOONmjlzps4++2w9+uij6t69u5544okWz3E4HBowYED0kZube0pFAwAAAMCJxBV06uvrtWHDBhUWFja+QEaGCgsLVVFR0eJ5H3/8sYYOHaq8vDx5vV69/fbbJ7xOXV2damtrYx4AAAAA0FpxBZ2DBw8qHA43GZHJzc1VdXV1s+cMHz5cTzzxhAKBgJ555hk1NDRowoQJ2rNnT4vXKS0tVU5OTvSRl5cXT5kAAAAA0lyHLy89fvx4TZ8+XaNHj9akSZO0cuVK9evXT4899liL58ybN0+hUCj62L17d0eXCaCdmKbk89HwEwAAJFZcy0v37dtXTqdTNTU1Mftramo0YMCAVr1G165dde655+q9995r8RiXyyWXyxVPaQCSgGlKXm+kF87ixZHlollBDQAAJEJcIzqZmZkaM2aMysrKovsaGhpUVlam8ePHt+o1wuGw3nrrLQ0cODC+SgEkvWCwseGn0xnpiQMAAJAIcU9dKy4u1uOPP66nnnpKW7Zs0U033aTDhw9r5syZkqTp06dr3rx50ePvvvtuvfzyy9q2bZs2btyoa6+9Vjt37tQNN9zQfu8CQFLweBpDTjgcafwJAACQCHFNXZOkqVOn6sCBA5o/f76qq6s1evRorV69OrpAwa5du5SR0ZifPvzwQ914442qrq7W5z//eY0ZM0avv/66zj777PZ7FwCSgmFEpquVl0dCDtPWAABAojgsy7ISXcTJ1NbWKicnR6FQSNnZ2YkuBwAAAECCtDYbdPiqawAAAADQ2Qg6AAAAAGyHoAMAAADAdgg6AAAAAGyHoAOgWaYp+XyRLQAAQKoh6ABowjQlr1fy+yNbwg4AAEg1BB0ATQSDjU0/nc5IXxwAAIBUQtAB0ITH0xhywuFI808AAIBU0iXRBQBIPoYhBQKRkRy3O/JnAACAVELQAdAswyDgAACA1MXUNQAAAAC2Q9ABAAAAYDsEHQAAAAC2Q9ABAAAAYDsEHcDGTFPy+Wj4CQAA0g9BB7Ap05S8Xsnvj2wJOwAAIJ0QdACbCgYbG346nZGeOAAAAOmCoAPYlMfTGHLC4UjjTwAAgHRBw1DApgxDCgQiIzluN80/AQBAeiHoADZmGAQcAACQnpi6BgAAAMB2CDoAAAAAbIegAwAAAMB2CDoAAAAAbIegA6QA05R8Ppp+AgAAtBZBB0hypil5vZLfH9kSdgAAAE6OoAMkuWCwsemn0xnpiwMAAIATI+gASc7jaQw54XCk+ScAAABOjIahQJIzDCkQiIzkuN00AAUAAGgNgg6QAgyDgAMAABAPpq4BAAAAsB2CDgAAAADbIegAAAAAsB2CDgAAAADbIegAncg0JZ+Ppp8AAAAdjaADdBLTlLxeye+PbAk7AAAAHYegA3SSYLCx6afTGemLAwAAgI5B0AE6icfTGHLC4UjzTwAAAHQMGoYCncQwpEAgMpLjdtMAFAAAoCMRdIBOZBgEHAAAgM7A1DUAAAAAtkPQAQAAAGA7BB0AAAAAtkPQAQAAAGA7BB0gTqYp+Xw0/AQAAEhmBB0gDqYpeb2S3x/ZEnYAAACSE0EHiEMw2Njw0+mM9MQBAABA8iHoAHHweBpDTjgcafwJAACA5EPDUCAOhiEFApGRHLeb5p8AAADJiqADxMkwCDgAAADJjqlrAAAAAGyHoAMAAADAdgg6AAAAAGyHoAMAAADAdgg6SFumKfl8NP0EAACwI4IO0pJpSl6v5PdHtoQdAAAAeyHoIC0Fg41NP53OSF8cAAAA2AdBB2nJ42kMOeFwpPknAAAA7IOGoUhLhiEFApGRHLebBqAAAAB2Q9BB2jIMAg4AAIBdMXUNAAAAgO20KegsWbJE+fn5ysrKUkFBgdavX9+q85YvXy6Hw6EpU6a05bIAAAAA0CpxB50VK1aouLhYJSUl2rhxo0aNGqWioiLt37//hOft2LFDt912my688MI2FwsAAAAArRF30Fm0aJFuvPFGzZw5U2effbYeffRRde/eXU888USL54TDYX3nO9/RwoULdfrpp5/0GnV1daqtrY15AAAAAEBrxRV06uvrtWHDBhUWFja+QEaGCgsLVVFR0eJ5d999t/r376/rr7++VdcpLS1VTk5O9JGXlxdPmUgzpin5fDT9BAAAQKO4gs7BgwcVDoeVm5sbsz83N1fV1dXNnrNu3TotXbpUjz/+eKuvM2/ePIVCoehj9+7d8ZSJNGKaktcr+f2RLWEHAAAAUgevunbo0CFNmzZNjz/+uPr27dvq81wul7Kzs2MeQHOCwcamn05npC8OAAAAEFcfnb59+8rpdKqmpiZmf01NjQYMGNDk+Pfff187duzQ5MmTo/saGhoiF+7SRZWVlTrjjDPaUjcgSfJ4pMWLG8OO253oigAAAJAM4hrRyczM1JgxY1RWVhbd19DQoLKyMo0fP77J8WeddZbeeustbdq0KfowDEMej0ebNm3iuzc4ZYYhBQLSrbdGtjQABQAAgBTniI4kFRcXa8aMGRo7dqzGjRunxYsX6/Dhw5o5c6Ykafr06Ro8eLBKS0uVlZWlL3/5yzHn9+rVS5Ka7AfayjAIOAAAAIgVd9CZOnWqDhw4oPnz56u6ulqjR4/W6tWrowsU7Nq1SxkZHfrVHwAAAAA4IYdlWVaiiziZ2tpa5eTkKBQKsTABAAAAkMZamw0YegEAAABgOwQdAAAAALZD0EFSME3J56PhJwAAANoHQQcJZ5qS1yv5/ZEtYQcAAACniqCDhAsGGxt+Op1SeXmiKwIAAECqI+gg4TyexpATDktud6IrAgAAQKqLu48O0N4MQwoEIiM5bjfNPwEAAHDqCDpICoZBwAEAAED7YeoaAAAAANsh6AAAAACwHYIOAAAAANsh6AAAAACwHYIO2pVpSj4fTT8BAACQWAQdtBvTlLxeye+PbAk7AAAASBSCDtpNMNjY9NPpjPTFAQAAABKBoIN24/E0hpxwONL8EwAAAEgEGoai3RiGFAhERnLcbhqAAgAAIHEIOmhXhkHAAQAAQOIxdQ0AAACA7RB0AAAAANgOQQcAAACA7RB0AAAAANgOQQdNmKbk89HwEwAAAKmLoIMYpil5vZLfH9kSdgAAAJCKCDqIEQw2Nvx0OiM9cQAAAIBUQ9BBDI+nMeSEw5HGnwAAAECqoWEoYhiGFAhERnLcbpp/AgAAIDURdNCEYRBwAAAAkNqYugYAAADAdgg6AAAAAGyHoAMAAADAdgg6AAAAAGyHoGNjpin5fDT9BAAAQPoh6NiUaUper+T3R7aEHQAAAKQTgo5NBYONTT+dzkhfHAAAACBdEHRsyuNpDDnhcKT5JwAAAJAuaBhqU4YhBQKRkRy3mwagAAAASC8EHRszDAIOAAAA0hNT1wAAAADYDkEHAAAAgO0QdAAAAADYDkEHAAAAgO0QdFKAaUo+H00/AQAAgNYi6CQ505S8Xsnvj2wJOwAAAMDJEXSSXDDY2PTT6Yz0xQEAAABwYgSdJOfxNIaccDjS/BMAAADAidEwNMkZhhQIREZy3G4agAIAAACtQdBJAYZBwAEAAADiwdQ1AAAAALZD0AEAAABgOwQdAAAAALZD0AEAAABgOwSdTmKaks9Hw08AAACgMxB0OoFpSl6v5PdHtoQdAAAAoGMRdDpBMNjY8NPpjPTEAQAAANBxCDqdwONpDDnhcKTxJwAAAICOQ8PQTmAYUiAQGclxu2n+CQAAAHQ0gk4nMQwCDgAAANBZmLoGAAAAwHYIOgAAAABsp01BZ8mSJcrPz1dWVpYKCgq0fv36Fo9duXKlxo4dq169eulzn/ucRo8eraeffrrNBQMAAADAycQddFasWKHi4mKVlJRo48aNGjVqlIqKirR///5mj+/du7fuuOMOVVRU6J///KdmzpypmTNn6k9/+tMpFw8AAAAAzXFYlmXFc0JBQYHOP/98PfTQQ5KkhoYG5eXl6ZZbbtHcuXNb9RrnnXeeLrvsMt1zzz2tOr62tlY5OTkKhULKzs6Op9x2Z5qRvjgeD4sLAAAAAJ2ttdkgrhGd+vp6bdiwQYWFhY0vkJGhwsJCVVRUnPR8y7JUVlamyspKffWrX23xuLq6OtXW1sY8koFpSl6v5PdHtqaZ6IoAAAAANCeuoHPw4EGFw2Hl5ubG7M/NzVV1dXWL54VCIfXo0UOZmZm67LLL5Pf7dfHFF7d4fGlpqXJycqKPvLy8eMrsMMFgY9NPpzPSFwcAAABA8umUVdd69uypTZs26W9/+5vuvfdeFRcXq/wEKWHevHkKhULRx+7duzujzJPyeBpDTjgcaf4JAAAAIPnE1TC0b9++cjqdqqmpidlfU1OjAQMGtHheRkaGvvCFL0iSRo8erS1btqi0tFTuFpKCy+WSy+WKp7ROYRhSIBAZyXG7+Y4OAAAAkKziGtHJzMzUmDFjVFZWFt3X0NCgsrIyjR8/vtWv09DQoLq6ungunTQMQ1q0iJADAAAAJLO4RnQkqbi4WDNmzNDYsWM1btw4LV68WIcPH9bMmTMlSdOnT9fgwYNVWloqKfJ9m7Fjx+qMM85QXV2dXnrpJT399NN65JFH2vedAAAAAMD/E3fQmTp1qg4cOKD58+erurpao0eP1urVq6MLFOzatUsZGY0DRYcPH9YPfvAD7dmzR926ddNZZ52lZ555RlOnTm2/dwEAAAAAnxF3H51ESKY+OgAAAAASp0P66AAAAABAKiDoAAAAALAdgg4AAAAA2yHoAAAAALAdgg4AAAAA2yHoAAAAALAdgg4AAAAA2yHoAAAAALAdgg4AAAAA2yHoAAAAALAdgg4AAAAA2yHoAAAAALAdgg4AAAAA2yHoAAAAALAdgg4AAAAA2yHoAAAAALCdLokuoDUsy5Ik1dbWJrgSAAAAAIl0PBMczwgtSYmgc+jQIUlSXl5egisBAAAAkAwOHTqknJycFp93WCeLQkmgoaFBe/fuVc+ePeVwOBJaS21trfLy8rR7925lZ2cntBakHu4fnAruH7QV9w5OBfcPTkVH3D+WZenQoUMaNGiQMjJa/iZOSozoZGRkaMiQIYkuI0Z2djY/7Ggz7h+cCu4ftBX3Dk4F9w9ORXvfPycayTmOxQgAAAAA2A5BBwAAAIDtEHTi5HK5VFJSIpfLlehSkIK4f3AquH/QVtw7OBXcPzgVibx/UmIxAgAAAACIByM6AAAAAGyHoAMAAADAdgg6AAAAAGyHoAMAAADAdgg6AAAAAGyHoNOMJUuWKD8/X1lZWSooKND69etPePyzzz6rs846S1lZWRo5cqReeumlTqoUySie++fxxx/XhRdeqM9//vP6/Oc/r8LCwpPeb7CveP/tOW758uVyOByaMmVKxxaIpBbv/fPRRx9p9uzZGjhwoFwul84880z+/yuNxXv/LF68WMOHD1e3bt2Ul5cnn8+nI0eOdFK1SBavvvqqJk+erEGDBsnhcOjFF1886Tnl5eU677zz5HK59IUvfEHLli3rsPoIOv9hxYoVKi4uVklJiTZu3KhRo0apqKhI+/fvb/b4119/XVdffbWuv/56vfnmm5oyZYqmTJmizZs3d3LlSAbx3j/l5eW6+uqrFQwGVVFRoby8PF1yySWqqqrq5MqRaPHeO8ft2LFDt912my688MJOqhTJKN77p76+XhdffLF27Nih5557TpWVlXr88cc1ePDgTq4cySDe++d3v/ud5s6dq5KSEm3ZskVLly7VihUr9OMf/7iTK0eiHT58WKNGjdKSJUtadfz27dt12WWXyePxaNOmTfrv//5v3XDDDfrTn/7UMQVaiDFu3Dhr9uzZ0T+Hw2Fr0KBBVmlpabPHX3nlldZll10Ws6+goMD6/ve/36F1IjnFe//8p2PHjlk9e/a0nnrqqY4qEUmqLffOsWPHrAkTJli//vWvrRkzZlher7cTKkUyivf+eeSRR6zTTz/dqq+v76wSkcTivX9mz55tfe1rX4vZV1xcbE2cOLFD60Ryk2S98MILJzxmzpw51pe+9KWYfVOnTrWKioo6pCZGdD6jvr5eGzZsUGFhYXRfRkaGCgsLVVFR0ew5FRUVMcdLUlFRUYvHw77acv/8p08++URHjx5V7969O6pMJKG23jt33323+vfvr+uvv74zykSSasv9Y5qmxo8fr9mzZys3N1df/vKXdd999ykcDndW2UgSbbl/JkyYoA0bNkSnt23btk0vvfSSvvGNb3RKzUhdnf17c5cOedUUdfDgQYXDYeXm5sbsz83N1datW5s9p7q6utnjq6urO6xOJKe23D//6fbbb9egQYOa/CMAe2vLvbNu3TotXbpUmzZt6oQKkczacv9s27ZNr7zyir7zne/opZde0nvvvacf/OAHOnr0qEpKSjqjbCSJttw/11xzjQ4ePKgLLrhAlmXp2LFjmjVrFlPXcFIt/d5cW1urTz/9VN26dWvX6zGiAySJ+++/X8uXL9cLL7ygrKysRJeDJHbo0CFNmzZNjz/+uPr27ZvocpCCGhoa1L9/f/3qV7/SmDFjNHXqVN1xxx169NFHE10aUkB5ebnuu+8+Pfzww9q4caNWrlypVatW6Z577kl0aUAMRnQ+o2/fvnI6naqpqYnZX1NTowEDBjR7zoABA+I6HvbVlvvnuAceeED333+/1qxZo3POOacjy0QSivfeef/997Vjxw5Nnjw5uq+hoUGS1KVLF1VWVuqMM87o2KKRNNryb8/AgQPVtWtXOZ3O6L4RI0aourpa9fX1yszM7NCakTzacv/cddddmjZtmm644QZJ0siRI3X48GF973vf0x133KGMDP47OprX0u/N2dnZ7T6aIzGiEyMzM1NjxoxRWVlZdF9DQ4PKyso0fvz4Zs8ZP358zPGS9Oc//7nF42Ffbbl/JOl///d/dc8992j16tUaO3ZsZ5SKJBPvvXPWWWfprbfe0qZNm6IPwzCiq9jk5eV1ZvlIsLb82zNx4kS999570YAsSe+++64GDhxIyEkzbbl/PvnkkyZh5nhojnwnHWhep//e3CFLHKSw5cuXWy6Xy1q2bJn1zjvvWN/73vesXr16WdXV1ZZlWda0adOsuXPnRo9/7bXXrC5dulgPPPCAtWXLFqukpMTq2rWr9dZbbyXqLSCB4r1/7r//fiszM9N67rnnrH379kUfhw4dStRbQILEe+/8J1ZdS2/x3j+7du2yevbsad18881WZWWl9cc//tHq37+/9ZOf/CRRbwEJFO/9U1JSYvXs2dP6/e9/b23bts16+eWXrTPOOMO68sorE/UWkCCHDh2y3nzzTevNN9+0JFmLFi2y3nzzTWvnzp2WZVnW3LlzrWnTpkWP37Ztm9W9e3frf/7nf6wtW7ZYS5YssZxOp7V69eoOqY+g0wy/32+ddtppVmZmpjVu3DjrjTfeiD43adIka8aMGTHH/+EPf7DOPPNMKzMz0/rSl75krVq1qpMrRjKJ5/4ZOnSoJanJo6SkpPMLR8LF+2/PZxF0EO/98/rrr1sFBQWWy+WyTj/9dOvee++1jh071slVI1nEc/8cPXrUWrBggXXGGWdYWVlZVl5envWDH/zA+vDDDzu/cCRUMBhs9veY4/fLjBkzrEmTJjU5Z/To0VZmZqZ1+umnW08++WSH1eewLMYYAQAAANgL39EBAAAAYDsEHQAAAAC2Q9ABAAAAYDsEHQAAAAC2Q9ABAAAAYDsEHQAAAAC2Q9ABAAAAYDsEHQAAAAC2Q9ABAAAAYDsEHQAAAAC2Q9ABAAAAYDv/P+xztN0G3/h0AAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 1000x700 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_predictions(X_train,y_train,X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building a PytorchTensor Linear Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('linear_layer.weight', tensor([[0.7645]])),\n",
       "             ('linear_layer.bias', tensor([0.8300]))])"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a linear model by subclassing nn.Module\n",
    "class LinearRegressionModelV2(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # Use nn.Linear() for createing the model Paramters\n",
    "        self.linear_layer=nn.Linear(in_features=1,out_features=1)\n",
    "\n",
    "    def forward(self,x:torch.Tensor)->torch.Tensor:\n",
    "        return self.linear_layer(x)\n",
    "torch.manual_seed(42)\n",
    "model_1=LinearRegressionModelV2()\n",
    "model_1.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set the model to use the target device\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(model_1.parameters()).device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegressionModelV2(\n",
       "  (linear_layer): Linear(in_features=1, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_1.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('linear_layer.weight', tensor([[0.7645]], device='cuda:0')),\n",
       "             ('linear_layer.bias', tensor([0.8300], device='cuda:0'))])"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_1.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn=nn.L1Loss()\n",
    "\n",
    "optimizer=torch.optim.SGD(params=model_1.parameters(),lr=0.01,)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0| Loss:0.5551779866218567 | Test loss:0.5739762187004089\n",
      "Epoch 10| Loss:0.439968079328537 | Test loss:0.4392664134502411\n",
      "Epoch 20| Loss:0.3247582018375397 | Test loss:0.30455657839775085\n",
      "Epoch 30| Loss:0.20954833924770355 | Test loss:0.16984669864177704\n",
      "Epoch 40| Loss:0.09433845430612564 | Test loss:0.03513690456748009\n",
      "Epoch 50| Loss:0.023886388167738914 | Test loss:0.04784907028079033\n",
      "Epoch 60| Loss:0.019956795498728752 | Test loss:0.045803118497133255\n",
      "Epoch 70| Loss:0.016517987474799156 | Test loss:0.037530567497015\n",
      "Epoch 80| Loss:0.013089174404740334 | Test loss:0.02994490973651409\n",
      "Epoch 90| Loss:0.009653178043663502 | Test loss:0.02167237363755703\n",
      "Epoch 100| Loss:0.006215683650225401 | Test loss:0.014086711220443249\n",
      "Epoch 110| Loss:0.00278724217787385 | Test loss:0.005814164876937866\n",
      "Epoch 120| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 130| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 140| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 150| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 160| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 170| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 180| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 190| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 200| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 210| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 220| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 230| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 240| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 250| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 260| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 270| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 280| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 290| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 300| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 310| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 320| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 330| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 340| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 350| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 360| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 370| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 380| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 390| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 400| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 410| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 420| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 430| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 440| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 450| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 460| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 470| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 480| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 490| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 500| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 510| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 520| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 530| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 540| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 550| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 560| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 570| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 580| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 590| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 600| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 610| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 620| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 630| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 640| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 650| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 660| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 670| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 680| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 690| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 700| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 710| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 720| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 730| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 740| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 750| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 760| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 770| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 780| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 790| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 800| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 810| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 820| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 830| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 840| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 850| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 860| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 870| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 880| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 890| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 900| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 910| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 920| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 930| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 940| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 950| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 960| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 970| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 980| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 990| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 1000| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 1010| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 1020| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 1030| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 1040| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 1050| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 1060| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 1070| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 1080| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 1090| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 1100| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 1110| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 1120| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 1130| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 1140| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 1150| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 1160| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 1170| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 1180| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 1190| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 1200| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 1210| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 1220| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 1230| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 1240| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 1250| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 1260| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 1270| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 1280| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 1290| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 1300| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 1310| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 1320| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 1330| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 1340| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 1350| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 1360| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 1370| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 1380| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 1390| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 1400| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 1410| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 1420| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 1430| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 1440| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 1450| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 1460| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 1470| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 1480| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 1490| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 1500| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 1510| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 1520| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 1530| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 1540| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 1550| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 1560| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 1570| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 1580| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 1590| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 1600| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 1610| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 1620| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 1630| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 1640| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 1650| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 1660| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 1670| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 1680| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 1690| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 1700| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 1710| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 1720| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 1730| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 1740| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 1750| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 1760| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 1770| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 1780| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 1790| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 1800| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 1810| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 1820| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 1830| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 1840| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 1850| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 1860| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 1870| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 1880| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 1890| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 1900| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 1910| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 1920| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 1930| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 1940| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 1950| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 1960| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 1970| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 1980| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 1990| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 2000| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 2010| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 2020| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 2030| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 2040| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 2050| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 2060| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 2070| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 2080| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 2090| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 2100| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 2110| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 2120| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 2130| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 2140| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 2150| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 2160| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 2170| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 2180| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 2190| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 2200| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 2210| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 2220| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 2230| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 2240| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 2250| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 2260| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 2270| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 2280| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 2290| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 2300| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 2310| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 2320| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 2330| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 2340| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 2350| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 2360| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 2370| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 2380| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 2390| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 2400| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 2410| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 2420| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 2430| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 2440| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 2450| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 2460| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 2470| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 2480| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 2490| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 2500| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 2510| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 2520| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 2530| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 2540| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 2550| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 2560| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 2570| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 2580| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 2590| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 2600| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 2610| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 2620| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 2630| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 2640| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 2650| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 2660| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 2670| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 2680| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 2690| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 2700| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 2710| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 2720| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 2730| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 2740| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 2750| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 2760| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 2770| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 2780| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 2790| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 2800| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 2810| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 2820| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 2830| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 2840| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 2850| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 2860| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 2870| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 2880| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 2890| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 2900| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 2910| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 2920| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 2930| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 2940| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 2950| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 2960| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 2970| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 2980| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 2990| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 3000| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 3010| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 3020| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 3030| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 3040| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 3050| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 3060| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 3070| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 3080| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 3090| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 3100| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 3110| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 3120| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 3130| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 3140| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 3150| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 3160| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 3170| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 3180| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 3190| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 3200| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 3210| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 3220| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 3230| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 3240| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 3250| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 3260| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 3270| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 3280| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 3290| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 3300| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 3310| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 3320| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 3330| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 3340| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 3350| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 3360| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 3370| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 3380| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 3390| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 3400| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 3410| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 3420| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 3430| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 3440| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 3450| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 3460| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 3470| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 3480| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 3490| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 3500| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 3510| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 3520| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 3530| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 3540| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 3550| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 3560| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 3570| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 3580| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 3590| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 3600| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 3610| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 3620| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 3630| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 3640| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 3650| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 3660| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 3670| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 3680| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 3690| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 3700| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 3710| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 3720| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 3730| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 3740| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 3750| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 3760| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 3770| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 3780| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 3790| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 3800| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 3810| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 3820| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 3830| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 3840| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 3850| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 3860| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 3870| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 3880| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 3890| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 3900| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 3910| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 3920| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 3930| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 3940| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 3950| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 3960| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 3970| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 3980| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 3990| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 4000| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 4010| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 4020| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 4030| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 4040| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 4050| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 4060| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 4070| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 4080| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 4090| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 4100| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 4110| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 4120| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 4130| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 4140| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 4150| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 4160| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 4170| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 4180| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 4190| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 4200| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 4210| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 4220| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 4230| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 4240| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 4250| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 4260| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 4270| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 4280| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 4290| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 4300| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 4310| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 4320| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 4330| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 4340| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 4350| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 4360| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 4370| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 4380| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 4390| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 4400| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 4410| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 4420| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 4430| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 4440| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 4450| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 4460| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 4470| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 4480| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 4490| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 4500| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 4510| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 4520| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 4530| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 4540| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 4550| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 4560| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 4570| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 4580| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 4590| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 4600| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 4610| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 4620| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 4630| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 4640| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 4650| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 4660| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 4670| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 4680| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 4690| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 4700| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 4710| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 4720| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 4730| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 4740| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 4750| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 4760| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 4770| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 4780| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 4790| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 4800| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 4810| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 4820| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 4830| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 4840| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 4850| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 4860| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 4870| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 4880| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 4890| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 4900| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 4910| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 4920| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 4930| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 4940| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 4950| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 4960| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 4970| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 4980| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 4990| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 5000| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 5010| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 5020| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 5030| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 5040| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 5050| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 5060| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 5070| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 5080| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 5090| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 5100| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 5110| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 5120| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 5130| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 5140| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 5150| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 5160| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 5170| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 5180| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 5190| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 5200| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 5210| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 5220| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 5230| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 5240| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 5250| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 5260| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 5270| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 5280| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 5290| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 5300| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 5310| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 5320| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 5330| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 5340| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 5350| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 5360| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 5370| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 5380| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 5390| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 5400| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 5410| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 5420| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 5430| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 5440| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 5450| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 5460| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 5470| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 5480| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 5490| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 5500| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 5510| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 5520| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 5530| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 5540| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 5550| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 5560| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 5570| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 5580| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 5590| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 5600| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 5610| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 5620| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 5630| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 5640| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 5650| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 5660| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 5670| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 5680| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 5690| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 5700| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 5710| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 5720| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 5730| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 5740| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 5750| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 5760| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 5770| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 5780| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 5790| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 5800| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 5810| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 5820| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 5830| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 5840| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 5850| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 5860| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 5870| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 5880| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 5890| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 5900| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 5910| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 5920| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 5930| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 5940| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 5950| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 5960| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 5970| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 5980| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 5990| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 6000| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 6010| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 6020| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 6030| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 6040| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 6050| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 6060| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 6070| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 6080| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 6090| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 6100| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 6110| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 6120| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 6130| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 6140| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 6150| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 6160| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 6170| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 6180| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 6190| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 6200| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 6210| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 6220| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 6230| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 6240| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 6250| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 6260| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 6270| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 6280| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 6290| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 6300| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 6310| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 6320| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 6330| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 6340| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 6350| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 6360| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 6370| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 6380| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 6390| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 6400| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 6410| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 6420| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 6430| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 6440| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 6450| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 6460| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 6470| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 6480| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 6490| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 6500| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 6510| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 6520| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 6530| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 6540| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 6550| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 6560| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 6570| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 6580| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 6590| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 6600| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 6610| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 6620| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 6630| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 6640| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 6650| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 6660| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 6670| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 6680| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 6690| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 6700| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 6710| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 6720| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 6730| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 6740| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 6750| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 6760| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 6770| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 6780| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 6790| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 6800| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 6810| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 6820| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 6830| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 6840| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 6850| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 6860| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 6870| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 6880| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 6890| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 6900| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 6910| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 6920| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 6930| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 6940| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 6950| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 6960| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 6970| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 6980| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 6990| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 7000| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 7010| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 7020| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 7030| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 7040| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 7050| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 7060| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 7070| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 7080| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 7090| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 7100| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 7110| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 7120| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 7130| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 7140| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 7150| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 7160| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 7170| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 7180| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 7190| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 7200| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 7210| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 7220| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 7230| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 7240| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 7250| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 7260| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 7270| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 7280| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 7290| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 7300| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 7310| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 7320| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 7330| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 7340| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 7350| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 7360| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 7370| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 7380| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 7390| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 7400| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 7410| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 7420| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 7430| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 7440| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 7450| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 7460| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 7470| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 7480| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 7490| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 7500| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 7510| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 7520| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 7530| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 7540| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 7550| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 7560| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 7570| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 7580| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 7590| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 7600| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 7610| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 7620| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 7630| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 7640| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 7650| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 7660| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 7670| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 7680| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 7690| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 7700| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 7710| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 7720| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 7730| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 7740| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 7750| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 7760| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 7770| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 7780| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 7790| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 7800| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 7810| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 7820| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 7830| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 7840| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 7850| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 7860| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 7870| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 7880| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 7890| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 7900| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 7910| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 7920| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 7930| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 7940| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 7950| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 7960| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 7970| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 7980| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 7990| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 8000| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 8010| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 8020| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 8030| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 8040| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 8050| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 8060| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 8070| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 8080| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 8090| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 8100| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 8110| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 8120| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 8130| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 8140| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 8150| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 8160| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 8170| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 8180| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 8190| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 8200| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 8210| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 8220| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 8230| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 8240| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 8250| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 8260| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 8270| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 8280| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 8290| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 8300| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 8310| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 8320| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 8330| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 8340| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 8350| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 8360| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 8370| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 8380| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 8390| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 8400| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 8410| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 8420| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 8430| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 8440| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 8450| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 8460| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 8470| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 8480| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 8490| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 8500| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 8510| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 8520| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 8530| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 8540| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 8550| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 8560| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 8570| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 8580| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 8590| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 8600| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 8610| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 8620| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 8630| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 8640| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 8650| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 8660| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 8670| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 8680| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 8690| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 8700| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 8710| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 8720| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 8730| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 8740| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 8750| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 8760| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 8770| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 8780| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 8790| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 8800| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 8810| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 8820| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 8830| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 8840| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 8850| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 8860| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 8870| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 8880| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 8890| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 8900| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 8910| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 8920| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 8930| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 8940| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 8950| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 8960| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 8970| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 8980| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 8990| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 9000| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 9010| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 9020| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 9030| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 9040| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 9050| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 9060| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 9070| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 9080| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 9090| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 9100| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 9110| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 9120| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 9130| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 9140| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 9150| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 9160| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 9170| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 9180| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 9190| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 9200| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 9210| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 9220| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 9230| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 9240| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 9250| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 9260| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 9270| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 9280| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 9290| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 9300| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 9310| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 9320| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 9330| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 9340| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 9350| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 9360| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 9370| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 9380| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 9390| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 9400| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 9410| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 9420| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 9430| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 9440| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 9450| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 9460| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 9470| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 9480| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 9490| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 9500| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 9510| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 9520| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 9530| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 9540| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 9550| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 9560| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 9570| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 9580| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 9590| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 9600| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 9610| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 9620| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 9630| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 9640| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 9650| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 9660| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 9670| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 9680| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 9690| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 9700| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 9710| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 9720| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 9730| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 9740| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 9750| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 9760| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 9770| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 9780| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 9790| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 9800| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 9810| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 9820| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 9830| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 9840| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 9850| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 9860| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 9870| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 9880| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 9890| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 9900| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 9910| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 9920| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 9930| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 9940| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 9950| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 9960| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 9970| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 9980| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 9990| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 10000| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 10010| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 10020| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 10030| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 10040| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 10050| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 10060| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 10070| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 10080| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 10090| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 10100| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 10110| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 10120| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 10130| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 10140| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 10150| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 10160| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 10170| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 10180| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 10190| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 10200| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 10210| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 10220| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 10230| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 10240| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 10250| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 10260| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 10270| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 10280| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 10290| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 10300| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 10310| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 10320| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 10330| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 10340| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 10350| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 10360| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 10370| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 10380| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 10390| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 10400| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 10410| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 10420| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 10430| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 10440| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 10450| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 10460| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 10470| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 10480| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 10490| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 10500| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 10510| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 10520| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 10530| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 10540| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 10550| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 10560| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 10570| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 10580| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 10590| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 10600| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 10610| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 10620| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 10630| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 10640| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 10650| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 10660| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 10670| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 10680| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 10690| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 10700| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 10710| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 10720| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 10730| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 10740| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 10750| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 10760| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 10770| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 10780| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 10790| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 10800| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 10810| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 10820| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 10830| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 10840| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 10850| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 10860| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 10870| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 10880| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 10890| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 10900| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 10910| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 10920| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 10930| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 10940| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 10950| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 10960| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 10970| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 10980| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 10990| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 11000| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 11010| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 11020| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 11030| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 11040| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 11050| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 11060| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 11070| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 11080| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 11090| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 11100| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 11110| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 11120| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 11130| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 11140| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 11150| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 11160| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 11170| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 11180| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 11190| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 11200| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 11210| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 11220| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 11230| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 11240| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 11250| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 11260| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 11270| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 11280| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 11290| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 11300| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 11310| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 11320| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 11330| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 11340| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 11350| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 11360| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 11370| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 11380| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 11390| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 11400| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 11410| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 11420| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 11430| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 11440| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 11450| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 11460| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 11470| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 11480| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 11490| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 11500| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 11510| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 11520| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 11530| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 11540| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 11550| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 11560| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 11570| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 11580| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 11590| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 11600| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 11610| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 11620| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 11630| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 11640| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 11650| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 11660| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 11670| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 11680| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 11690| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 11700| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 11710| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 11720| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 11730| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 11740| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 11750| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 11760| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 11770| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 11780| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 11790| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 11800| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 11810| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 11820| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 11830| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 11840| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 11850| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 11860| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 11870| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 11880| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 11890| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 11900| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 11910| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 11920| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 11930| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 11940| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 11950| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 11960| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 11970| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 11980| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 11990| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 12000| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 12010| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 12020| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 12030| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 12040| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 12050| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 12060| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 12070| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 12080| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 12090| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 12100| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 12110| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 12120| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 12130| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 12140| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 12150| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 12160| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 12170| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 12180| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 12190| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 12200| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 12210| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 12220| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 12230| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 12240| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 12250| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 12260| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 12270| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 12280| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 12290| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 12300| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 12310| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 12320| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 12330| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 12340| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 12350| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 12360| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 12370| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 12380| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 12390| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 12400| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 12410| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 12420| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 12430| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 12440| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 12450| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 12460| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 12470| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 12480| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 12490| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 12500| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 12510| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 12520| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 12530| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 12540| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 12550| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 12560| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 12570| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 12580| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 12590| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 12600| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 12610| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 12620| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 12630| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 12640| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 12650| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 12660| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 12670| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 12680| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 12690| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 12700| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 12710| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 12720| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 12730| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 12740| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 12750| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 12760| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 12770| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 12780| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 12790| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 12800| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 12810| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 12820| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 12830| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 12840| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 12850| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 12860| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 12870| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 12880| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 12890| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 12900| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 12910| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 12920| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 12930| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 12940| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 12950| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 12960| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 12970| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 12980| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 12990| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 13000| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 13010| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 13020| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 13030| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 13040| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 13050| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 13060| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 13070| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 13080| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 13090| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 13100| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 13110| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 13120| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 13130| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 13140| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 13150| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 13160| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 13170| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 13180| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 13190| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 13200| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 13210| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 13220| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 13230| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 13240| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 13250| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 13260| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 13270| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 13280| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 13290| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 13300| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 13310| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 13320| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 13330| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 13340| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 13350| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 13360| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 13370| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 13380| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 13390| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 13400| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 13410| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 13420| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 13430| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 13440| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 13450| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 13460| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 13470| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 13480| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 13490| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 13500| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 13510| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 13520| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 13530| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 13540| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 13550| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 13560| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 13570| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 13580| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 13590| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 13600| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 13610| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 13620| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 13630| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 13640| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 13650| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 13660| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 13670| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 13680| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 13690| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 13700| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 13710| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 13720| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 13730| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 13740| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 13750| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 13760| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 13770| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 13780| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 13790| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 13800| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 13810| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 13820| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 13830| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 13840| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 13850| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 13860| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 13870| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 13880| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 13890| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 13900| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 13910| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 13920| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 13930| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 13940| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 13950| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 13960| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 13970| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 13980| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 13990| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 14000| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 14010| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 14020| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 14030| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 14040| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 14050| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 14060| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 14070| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 14080| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 14090| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 14100| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 14110| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 14120| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 14130| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 14140| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 14150| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 14160| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 14170| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 14180| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 14190| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 14200| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 14210| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 14220| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 14230| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 14240| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 14250| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 14260| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 14270| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 14280| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 14290| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 14300| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 14310| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 14320| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 14330| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 14340| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 14350| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 14360| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 14370| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 14380| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 14390| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 14400| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 14410| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 14420| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 14430| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 14440| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 14450| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 14460| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 14470| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 14480| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 14490| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 14500| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 14510| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 14520| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 14530| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 14540| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 14550| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 14560| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 14570| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 14580| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 14590| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 14600| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 14610| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 14620| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 14630| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 14640| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 14650| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 14660| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 14670| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 14680| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 14690| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 14700| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 14710| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 14720| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 14730| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 14740| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 14750| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 14760| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 14770| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 14780| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 14790| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 14800| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 14810| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 14820| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 14830| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 14840| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 14850| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 14860| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 14870| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 14880| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 14890| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 14900| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 14910| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 14920| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 14930| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 14940| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 14950| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 14960| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 14970| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 14980| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 14990| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 15000| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 15010| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 15020| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 15030| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 15040| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 15050| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 15060| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 15070| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 15080| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 15090| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 15100| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 15110| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 15120| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 15130| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 15140| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 15150| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 15160| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 15170| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 15180| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 15190| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 15200| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 15210| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 15220| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 15230| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 15240| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 15250| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 15260| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 15270| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 15280| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 15290| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 15300| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 15310| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 15320| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 15330| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 15340| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 15350| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 15360| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 15370| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 15380| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 15390| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 15400| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 15410| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 15420| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 15430| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 15440| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 15450| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 15460| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 15470| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 15480| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 15490| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 15500| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 15510| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 15520| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 15530| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 15540| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 15550| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 15560| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 15570| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 15580| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 15590| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 15600| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 15610| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 15620| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 15630| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 15640| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 15650| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 15660| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 15670| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 15680| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 15690| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 15700| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 15710| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 15720| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 15730| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 15740| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 15750| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 15760| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 15770| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 15780| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 15790| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 15800| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 15810| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 15820| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 15830| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 15840| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 15850| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 15860| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 15870| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 15880| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 15890| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 15900| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 15910| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 15920| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 15930| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 15940| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 15950| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 15960| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 15970| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 15980| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 15990| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 16000| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 16010| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 16020| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 16030| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 16040| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 16050| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 16060| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 16070| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 16080| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 16090| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 16100| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 16110| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 16120| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 16130| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 16140| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 16150| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 16160| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 16170| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 16180| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 16190| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 16200| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 16210| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 16220| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 16230| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 16240| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 16250| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 16260| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 16270| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 16280| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 16290| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 16300| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 16310| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 16320| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 16330| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 16340| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 16350| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 16360| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 16370| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 16380| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 16390| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 16400| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 16410| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 16420| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 16430| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 16440| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 16450| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 16460| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 16470| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 16480| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 16490| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 16500| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 16510| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 16520| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 16530| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 16540| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 16550| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 16560| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 16570| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 16580| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 16590| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 16600| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 16610| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 16620| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 16630| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 16640| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 16650| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 16660| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 16670| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 16680| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 16690| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 16700| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 16710| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 16720| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 16730| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 16740| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 16750| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 16760| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 16770| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 16780| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 16790| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 16800| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 16810| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 16820| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 16830| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 16840| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 16850| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 16860| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 16870| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 16880| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 16890| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 16900| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 16910| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 16920| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 16930| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 16940| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 16950| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 16960| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 16970| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 16980| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 16990| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 17000| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 17010| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 17020| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 17030| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 17040| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 17050| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 17060| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 17070| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 17080| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 17090| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 17100| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 17110| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 17120| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 17130| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 17140| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 17150| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 17160| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 17170| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 17180| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 17190| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 17200| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 17210| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 17220| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 17230| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 17240| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 17250| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 17260| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 17270| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 17280| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 17290| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 17300| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 17310| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 17320| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 17330| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 17340| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 17350| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 17360| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 17370| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 17380| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 17390| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 17400| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 17410| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 17420| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 17430| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 17440| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 17450| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 17460| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 17470| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 17480| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 17490| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 17500| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 17510| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 17520| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 17530| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 17540| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 17550| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 17560| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 17570| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 17580| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 17590| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 17600| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 17610| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 17620| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 17630| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 17640| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 17650| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 17660| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 17670| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 17680| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 17690| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 17700| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 17710| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 17720| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 17730| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 17740| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 17750| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 17760| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 17770| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 17780| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 17790| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 17800| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 17810| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 17820| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 17830| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 17840| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 17850| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 17860| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 17870| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 17880| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 17890| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 17900| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 17910| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 17920| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 17930| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 17940| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 17950| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 17960| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 17970| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 17980| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 17990| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 18000| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 18010| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 18020| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 18030| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 18040| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 18050| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 18060| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 18070| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 18080| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 18090| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 18100| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 18110| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 18120| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 18130| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 18140| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 18150| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 18160| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 18170| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 18180| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 18190| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 18200| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 18210| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 18220| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 18230| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 18240| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 18250| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 18260| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 18270| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 18280| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 18290| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 18300| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 18310| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 18320| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 18330| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 18340| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 18350| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 18360| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 18370| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 18380| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 18390| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 18400| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 18410| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 18420| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 18430| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 18440| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 18450| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 18460| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 18470| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 18480| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 18490| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 18500| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 18510| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 18520| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 18530| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 18540| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 18550| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 18560| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 18570| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 18580| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 18590| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 18600| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 18610| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 18620| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 18630| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 18640| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 18650| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 18660| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 18670| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 18680| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 18690| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 18700| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 18710| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 18720| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 18730| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 18740| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 18750| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 18760| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 18770| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 18780| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 18790| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 18800| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 18810| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 18820| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 18830| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 18840| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 18850| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 18860| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 18870| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 18880| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 18890| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 18900| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 18910| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 18920| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 18930| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 18940| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 18950| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 18960| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 18970| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 18980| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 18990| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 19000| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 19010| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 19020| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 19030| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 19040| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 19050| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 19060| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 19070| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 19080| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 19090| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 19100| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 19110| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 19120| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 19130| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 19140| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 19150| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 19160| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 19170| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 19180| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 19190| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 19200| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 19210| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 19220| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 19230| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 19240| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 19250| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 19260| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 19270| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 19280| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 19290| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 19300| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 19310| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 19320| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 19330| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 19340| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 19350| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 19360| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 19370| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 19380| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 19390| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 19400| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 19410| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 19420| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 19430| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 19440| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 19450| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 19460| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 19470| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 19480| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 19490| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 19500| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 19510| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 19520| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 19530| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 19540| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 19550| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 19560| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 19570| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 19580| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 19590| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 19600| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 19610| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 19620| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 19630| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 19640| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 19650| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 19660| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 19670| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 19680| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 19690| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 19700| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 19710| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 19720| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 19730| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 19740| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 19750| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 19760| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 19770| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 19780| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 19790| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 19800| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 19810| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 19820| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 19830| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 19840| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 19850| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 19860| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 19870| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 19880| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 19890| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 19900| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 19910| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 19920| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 19930| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 19940| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 19950| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 19960| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 19970| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 19980| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n",
      "Epoch 19990| Loss:0.0012645035749301314 | Test loss:0.013801801018416882\n"
     ]
    }
   ],
   "source": [
    "# training Loss\n",
    "torch.manual_seed(42)\n",
    "# put data on the target device\n",
    "X_train=X_train.to(device)\n",
    "y_train=y_train.to(device)\n",
    "X_test=X_test.to(device)\n",
    "y_test=y_test.to(device)\n",
    "\n",
    "\n",
    "\n",
    "epochs=20000\n",
    "for epoch in range(epochs):\n",
    "    model_1.train()\n",
    "    y_pred=model_1(X_train)\n",
    "    loss=loss_fn(y_pred,y_train)\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    ### Testing \n",
    "    model_1.eval()\n",
    "    with torch.inference_mode():\n",
    "        test_pred=model_1(X_test)\n",
    "        test_loss=loss_fn(test_pred,y_test)\n",
    "\n",
    "    if epoch%10==0:\n",
    "        print(f\"Epoch {epoch}| Loss:{loss} | Test loss:{test_loss}\")\n",
    "       \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('linear_layer.weight', tensor([[0.7645]], device='cuda:0')),\n",
       "             ('linear_layer.bias', tensor([0.8300], device='cuda:0'))])"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_1.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.4416],\n",
       "        [1.4569],\n",
       "        [1.4722],\n",
       "        [1.4875],\n",
       "        [1.5028],\n",
       "        [1.5181],\n",
       "        [1.5334],\n",
       "        [1.5487],\n",
       "        [1.5640],\n",
       "        [1.5793]], device='cuda:0')"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Turn model into evaluation mode\n",
    "model_1.eval()\n",
    "\n",
    "with torch.inference_mode():\n",
    "    y_preds=model_1(X_test)\n",
    "y_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "MODEL_NAME=\"01_pytorch_workflow_model_1.pth\"\n",
    "MODEL_PATH=Path(MODEL_NAME)\n",
    "torch.save(model_1,MODEL_PATH)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('linear_layer.weight', tensor([[0.6968]], device='cuda:0')),\n",
       "             ('linear_layer.bias', tensor([0.3025], device='cuda:0'))])"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load a Pytorch Model\n",
    "loaded_model=torch.load(MODEL_PATH)\n",
    "loaded_model.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "next(loaded_model.state_dict())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
